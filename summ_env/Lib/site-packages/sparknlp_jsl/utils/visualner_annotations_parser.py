import json
import os

##################### VisualNER annotations (bounding boxes) to CONLL #####################

def visualner_annotations_to_conll(visual_json_input_file, conll_output_file):
    """
    Converts VisualNER JSON annotations to CONLL format.

    Parameters
    ----------
    visual_json_input_file : str
        Path to the input JSON file containing VisualNER annotations.
    conll_output_file : str
        Path to the output file where the CONLL formatted data will be saved.
    """
    conll_data = []

    # Load the JSON file
    with open(visual_json_input_file, "r") as f:
        data = json.load(f)

    # Process each annotation item in the JSON file
    for item in data:
        completions = item["completions"][0]["result"]
        ocr_texts = item["data"]["ocr_text"]

        # Process each OCR text token
        for tokens in ocr_texts:
            prev_label = "O"
            for i, token in enumerate(tokens):
                token_text = token["text"]
                label = "O"

                # Check if the token text is present in any of the annotation completions
                for completion in completions:
                    completion_text = [t["text"] for t in completion["tokens"]]
                    if token_text in completion_text:
                        label = completion["value"]["rectanglelabels"][0]

                # Adjust label prefix based on its type (O or not)
                label_prefix = "NN NN" if label == "O" else "NNP NNP"

                if label != "O":
                    # Use B- (beginning) or I- (inside) prefix based on previous label
                    if prev_label == "O" or label != prev_label[2:]:
                        label = "B-" + label
                    else:
                        label = "I-" + label

                # Create a CONLL formatted line for the token
                conll_line = f"{token_text} {label_prefix} {label}\n"
                conll_data.append(conll_line)
                prev_label = label

            conll_data.append("\n")
    
    # Write the generated CONLL data to the output file
    with open(conll_output_file, "w") as f:
        f.writelines(conll_data)

    print(f"{conll_output_file} is generated.")


##################### PDFs to VisualNER to CONLL #####################

def get_tokens(hocr):
    """
    Extracts tokens from HOCR data with their bounding box and label information.

    Parameters
    ----------
    hocr : list of dict
        List of HOCR data dictionaries.

    Returns
    -------
    list of dict
        Extracted tokens with bounding box and label information.
    """
    results = []
    for row in hocr:
        text = row["metadata"]["token"]
        if len(text.strip()) == 0:
            continue
        results.append(
            {
                "x": int(row["metadata"]['x']),
                "y": int(row["metadata"]['y']),
                "width": int(row["metadata"]['width']),
                "height": int(row["metadata"]['height']),
                "rotation": 0,
                "text": text,
                "label": row["result"]
            }
        )
    return results

def convert_to_CONLL(data, doc_id):
    """
    Converts token data to CONLL format.

    Parameters
    ----------
    data : list of dict
        List of token dictionaries with text and label information.
    doc_id : int
        Document ID for the CONLL file.

    Returns
    -------
    list of str
        List of CONLL formatted lines.
    """
    conll_lines = [f"-DOCSTART- -X- {doc_id} O \n"]
    for item in data:
        text = item['text']
        label = item['label']
        if label == 'other':
            conll_lines.append(f"{text} NN NN O")
        else:
            conll_lines.append(f"{text} NNP NNP {label}")
    return conll_lines

def write_CONLL(conll_lines, filename):
    """
    Writes CONLL lines to a file.

    Parameters
    ----------
    conll_lines : list of str
        List of CONLL formatted lines.
    filename : str
        Path to the output CONLL file.
    """
    with open(filename, 'w') as file:
        for line in conll_lines:
            file.write(line + '\n')

def pdfs_to_visualner_to_conll(spark, pdf_dir, pdf_visual_pipeline_model, output_file='Text_NER_Dataset.conll'):
    """
    Processes PDF files, extracts annotations using VisualNER, and converts to CONLL format.

    Parameters
    ----------
    spark : SparkSession
        Active Spark session.
    pdf_dir : str
        Directory containing PDF files to process.
    pdf_visual_pipeline_model : Model
        Pre-trained VisualNER pipeline model.
    output_file : str, optional
        Path to the output CONLL file. Default is 'Text_NER_Dataset.conll'.
    """
    print("Processing the PDF files has been started... \n")
    
    combined_conll_lines = []
    pdf_files = [f for f in os.listdir(pdf_dir) if f.endswith('.pdf')]
    doc_id = 1

    # Process each PDF file in the directory
    for pdf_file in pdf_files:
        df = spark.read.format("binaryFile").load(os.path.join(pdf_dir, pdf_file))
        data = pdf_visual_pipeline_model.transform(df)
        hocr = data.select("model").collect()[0].asDict()["model"]
        tokens_and_labels = [i for i in get_tokens(hocr)]
        conll_lines = convert_to_CONLL(tokens_and_labels, doc_id)
        combined_conll_lines.extend(conll_lines)
        combined_conll_lines.append('')
        doc_id += 1

    print("Pipeline processing DONE! \n")

    # Write the combined CONLL data to the output file
    write_CONLL(combined_conll_lines, output_file)
    print(output_file + " has been generated. \n")
