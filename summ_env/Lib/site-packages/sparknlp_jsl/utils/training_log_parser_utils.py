from collections import defaultdict


def aggregate_entities(metrics):
    metrics["entity"] = metrics.label.apply(lambda x: x.split("-")[-1])
    chart_metrics = metrics[["epoch", "set", "entity", "tp", "fp", "fn"]].groupby(["epoch", "entity", "set"]).sum()
    chart_metrics["prec"] = chart_metrics.tp / (chart_metrics.tp + chart_metrics.fp)
    chart_metrics["rec"] = chart_metrics.tp / (chart_metrics.tp + chart_metrics.fn)
    chart_metrics["f1"] = 2 * chart_metrics.prec * chart_metrics.rec / (chart_metrics.prec + chart_metrics.rec)
    return chart_metrics


def split_tag(chunk_tag):
    """Splits chunk tag into IOBES prefix and chunk_type.

    e.g.
    B-PER -> (B, PER)
    O -> (O, None)

    Args:
        chunk_tag(str): The chunk tag.
    """
    if chunk_tag == 'O':
        return 'O', None
    return chunk_tag.split('-', maxsplit=1)


def is_chunk_end(prev_tag, tag):
    """Checks if the previous chunk ended between the previous and current word.

    e.g.
    (B-PER, I-PER) -> False
    (B-LOC, O)  -> True
    
    Note: in case of contradicting tags, e.g. (B-PER, I-LOC)
    this is considered as (B-PER, B-LOC)

    Args:
        prev_tag(str): The previous chunk tag.
        tag(str): The current chunk tag.
    """
    prefix1, chunk_type1 = split_tag(prev_tag)
    prefix2, chunk_type2 = split_tag(tag)

    if prefix1 == 'O':
        return False
    if prefix2 == 'O':
        return prefix1 != 'O'

    if chunk_type1 != chunk_type2:
        return True

    return prefix2 in ['B', 'S'] or prefix1 in ['E', 'S']


def is_chunk_start(prev_tag, tag):
    """Checks if a new chunk started between the previous and current word.

    Args:
        prev_tag(str): The previous chunk tag.
        tag(str): The current chunk tag.
    """
    prefix1, chunk_type1 = split_tag(prev_tag)
    prefix2, chunk_type2 = split_tag(tag)

    if prefix2 == 'O':
        return False
    if prefix1 == 'O':
        return prefix2 != 'O'

    if chunk_type1 != chunk_type2:
        return True

    return prefix2 in ['B', 'S'] or prefix1 in ['E', 'S']


def calc_metrics(tp, p, t, percent=True):
    """Computes overall precision, recall and FB1.
    
    (default values are 0.0)
    if percent is True, return 100 * original decimal value

    Args:
        tp(int): The number of true positives.
        p(int): The number of predicted positives.
        t(int): The number of true positives.
        percent(bool, optional): If True, return 100 * original decimal value. Defaults to True.
    """
    precision = tp / p if p else 0
    recall = tp / t if t else 0
    fb1 = 2 * precision * recall / (precision + recall) if precision + recall else 0
    if percent:
        return 100 * precision, 100 * recall, 100 * fb1
    else:
        return precision, recall, fb1


def count_chunks(true_seqs, pred_seqs):
    """Counts the number of true positives, false positives and false negatives.

    Args:
        true_seqs(list): A list of true tags.
        pred_seqs(list): A list of predicted tags.
    

    Returns:
        tuple: A tuple containing the number of true positives, false positives and false negatives. 
            (correct_chunks, true_chunks, pred_chunks, correct_counts, true_counts, pred_counts), where:
            correct_chunks: a dict (counter) where key = chunk types, value = number of correctly identified chunks per type
            true_chunks: a dict, number of true chunks per type
            pred_chunks: a dict, number of identified chunks per type
            correct_counts, true_counts, pred_counts: similar to above, but for tags
    """
    correct_chunks = defaultdict(int)
    true_chunks = defaultdict(int)
    pred_chunks = defaultdict(int)

    correct_counts = defaultdict(int)
    true_counts = defaultdict(int)
    pred_counts = defaultdict(int)

    prev_true_tag, prev_pred_tag = 'O', 'O'
    correct_chunk = None

    for true_tag, pred_tag in zip(true_seqs, pred_seqs):
        if true_tag == pred_tag:
            correct_counts[true_tag] += 1
        true_counts[true_tag] += 1
        pred_counts[pred_tag] += 1

        _, true_type = split_tag(true_tag)
        _, pred_type = split_tag(pred_tag)

        if correct_chunk is not None:
            true_end = is_chunk_end(prev_true_tag, true_tag)
            pred_end = is_chunk_end(prev_pred_tag, pred_tag)

            if pred_end and true_end:
                correct_chunks[correct_chunk] += 1
                correct_chunk = None
            elif pred_end != true_end or true_type != pred_type:
                correct_chunk = None

        true_start = is_chunk_start(prev_true_tag, true_tag)
        pred_start = is_chunk_start(prev_pred_tag, pred_tag)

        if true_start and pred_start and true_type == pred_type:
            correct_chunk = true_type
        if true_start:
            true_chunks[true_type] += 1
        if pred_start:
            pred_chunks[pred_type] += 1

        prev_true_tag, prev_pred_tag = true_tag, pred_tag
    if correct_chunk is not None:
        correct_chunks[correct_chunk] += 1

    return (correct_chunks, true_chunks, pred_chunks,
            correct_counts, true_counts, pred_counts)


def get_result(correct_chunks, true_chunks, pred_chunks,
               correct_counts, true_counts, pred_counts, verbose=True):
    """Returns overall precision, recall and FB1 (default values are 0.0).

    if verbose, print overall performance, as well as performance per chunk type;
    otherwise, simply return overall prec, rec, f1 scores.

    Args:
        correct_chunks(dict): A dict (counter) where key = chunk types, value = number of correctly identified chunks per type.
        true_chunks(dict): A dict, number of true chunks per type.
        pred_chunks(dict): A dict, number of identified chunks per type.
        correct_counts(dict): A dict, number of correctly identified tags per type.
        true_counts(dict): A dict, number of true tags per type.
        pred_counts(dict): A dict, number of identified tags per type.
        verbose(bool, optional): If True, print overall performance, as well as performance per chunk type. Defaults to True.
    """
    # sum counts
    sum_correct_chunks = sum(correct_chunks.values())
    sum_true_chunks = sum(true_chunks.values())
    sum_pred_chunks = sum(pred_chunks.values())

    sum_correct_counts = sum(correct_counts.values())
    sum_true_counts = sum(true_counts.values())

    nonO_correct_counts = sum(v for k, v in correct_counts.items() if k != 'O')
    nonO_true_counts = sum(v for k, v in true_counts.items() if k != 'O')

    chunk_types = sorted(list(set(list(true_chunks) + list(pred_chunks))))

    # compute overall precision, recall and FB1 (default values are 0.0)
    prec, rec, f1 = calc_metrics(sum_correct_chunks, sum_pred_chunks, sum_true_chunks)
    res = (prec, rec, f1)
    if not verbose:
        return res

    # print overall performance, and performance per chunk type

    print("processed %i tokens with %i phrases; " % (sum_true_counts, sum_true_chunks), end='')
    print("found: %i phrases; correct: %i.\n" % (sum_pred_chunks, sum_correct_chunks), end='')

    print("accuracy: %6.2f%%; (non-O)" % (100 * nonO_correct_counts / nonO_true_counts))
    print("accuracy: %6.2f%%; " % (100 * sum_correct_counts / sum_true_counts), end='')
    print("precision: %6.2f%%; recall: %6.2f%%; FB1: %6.2f" % (prec, rec, f1))

    # for each chunk type, compute precision, recall and FB1 (default values are 0.0)
    chunk_metrics = []
    for t in chunk_types:
        prec, rec, f1 = calc_metrics(correct_chunks[t], pred_chunks[t], true_chunks[t])

        print("%17s: " % t, end='')
        print("precision: %6.2f%%; recall: %6.2f%%; FB1: %6.2f" %
              (prec, rec, f1), end='')
        print("  %d" % pred_chunks[t])

        chunk_metrics.append((t, prec, rec, f1, pred_chunks[t]))

    return res, chunk_metrics
