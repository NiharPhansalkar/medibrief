from sparknlp.base import *
import pandas as pd
from pyspark.sql.functions import monotonically_increasing_id
from sparknlp_jsl.annotator import *
from sparknlp.pretrained import PretrainedPipeline
from pyspark.sql import functions as f
from sparknlp_jsl.annotator.deid.deIdentification import DeIdentification

class Deidentifier:
    def __init__(self,
                 spark,
                 custom_pipeline=None,
                 fields=None,
                 ner_chunk="ner_chunk",
                 sentence="sentence",
                 token="token",
                 document="document",
                 masking_policy="entity_labels",
                 fixed_mask_length=1,
                 obfuscate_date=True,
                 obfuscate_ref_source="faker",
                 obfuscate_ref_file_path=None,
                 age_group_obfuscation=False,
                 age_ranges=None,
                 shift_days=False,
                 number_of_days=None,
                 documenthashcoder_col_name="documentHash",
                 date_tag="DATE",
                 language="en",
                 region="us",
                 unnormalized_date=False,
                 unnormalized_mode="mask",
                 id_column_name="id",
                 date_shift_column_name="dateshift",
                 multi_mode_file_path=None,
                 domain=None,
                 separator="\t",
                 input_file_path=None,
                 output_file_path="deidentified.csv",
                 ):

        """ This class is used to deidentify the given data.
        
        Parameters
        ----------
        spark : SparkSession
            SparkSession object
        custom_pipeline : Sparknlp PipelineModel, optional
            custom PipelineModel to be used for deidentification, by default None
        ner_chunk : str, optional
            final chunk column name of custom pipeline that will be deidentified, by default "ner_chunk"
        fields : dict, optional
            fields to be deidentified and their deidentification modes, by default {"text": "mask"}
        sentence : str, optional
            sentence column name of the given custom pipeline, by default "sentence"
        token : str, optional
            token column name of the given custom pipeline, by default "token"
        document : str, optional
            document column name of the given custom pipeline, by default "document"
        masking_policy : str, optional
            masking policy, by default "entity_labels"
        fixed_mask_length : int, optional
            fixed mask length, by default 4
        obfuscate_date : bool, optional
            obfuscate date, by default True
        obfuscate_ref_source : str, optional
            obfuscate reference source, by default "faker"
        obfuscate_ref_file_path : str, optional
            obfuscate reference file path, by default None
        age_group_obfuscation : bool, optional
            age group obfuscation, by default False
        age_ranges : list, optional
            age ranges for obfuscation, by default [1, 4, 12, 20, 40, 60, 80]
        shift_days : bool, optional
            shift days, by default False
        number_of_days : int, optional
            number of days, by default None
        documenthashcoder_col_name : str, optional
            document hash coder column name, by default "documentHash"
        date_tag : str, optional
            date tag, by default "DATE"
        language : str, optional
            language, by default "en"
        region : str, optional
            region, by default "us"
        unnormalized_date : bool, optional
            unnormalized date, by default False
        unnormalized_mode : str, optional
            unnormalized mode, by default "mask"
        id_column_name : str, optional
            ID column name, by default "id"
        date_shift_column_name : str, optional
            date shift column name, by default "date_shift"
        multi_mode_file_path: str, optional
            json file path for multi-mode Deid
        domain: str, optional
            domain to apply deid using pretrained pipeline, by default "clinical"
        separator : str, optional
            separator of input csv file, by default "\t"
        input_file_path : str, optional
            input file path, by default None
        output_file_path : str, optional
            output file path, by default 'deidentified.csv'

        Returns
        -------
        Spark DataFrame
            Spark DataFrame with deidentified text
        csv/json file
            A deidentified file.

        """

        self.spark = spark
        self.custom_pipeline = custom_pipeline
        self.ner_chunk = ner_chunk
        self.sentence = sentence
        self.token = token
        self.document = document
        self.masking_policy = masking_policy
        self.fixed_mask_length = fixed_mask_length
        self.obfuscate_date = obfuscate_date
        self.obfuscate_ref_source = obfuscate_ref_source
        self.obfuscate_ref_file_path = obfuscate_ref_file_path
        self.age_group_obfuscation = age_group_obfuscation
        self.age_ranges = age_ranges
        self.shift_days = shift_days
        self.number_of_days = number_of_days
        self.documenthashcoder_col_name = documenthashcoder_col_name
        self.date_tag = date_tag
        self.language = language
        self.region = region
        self.unnormalized_date = unnormalized_date
        self.unnormalized_mode = unnormalized_mode
        self.id_column_name = id_column_name
        self.date_shift_column_name = date_shift_column_name
        self.fields = fields
        self.separator = separator
        self.multi_mode_file_path = multi_mode_file_path
        self.domain = domain
        self.input_file_path = input_file_path
        self.custom_pipeline = custom_pipeline
        self.output_file_path = output_file_path

    def deidentify(self):
        """This function deidentifies the input file according to the given field names and saves the results as a csv/json file.
        """

        if not self.fields:
            self.fields = {"text": "mask"}

        if not self.age_ranges:
            self.age_ranges = [1, 4, 12, 20, 40, 60, 80]

        # check if the given mode is valid
        mode_list = ["mask", "obfuscate"]
        entered_mode_list = list(self.fields.values())
        try:
            for m in entered_mode_list:
                if m not in mode_list:
                    raise ValueError(
                        "You entered an invalid mode option. Please enter 'mask' or 'obfuscate'..."
                    )

        except ValueError as e:
            print(e)

        # check if the given unnormalized mode is valid
        unnormalized_mode_list = ["mask", "obfuscate"]
        try:
            if self.unnormalized_mode not in unnormalized_mode_list:
                raise ValueError(
                    "You entered an invalid unnormalized mode option. Please enter 'mask' or 'obfuscate'..."
                )
        except ValueError as e:
            print(e)

        # check if the given masking policy is valid
        masking_policy_list = [
            "entity_labels",
            "same_length_chars",
            "fixed_length_chars",
        ]
        try:
            if self.masking_policy not in masking_policy_list:
                raise ValueError(
                    "You entered an invalid masking policy option. Please enter 'entity_labels', 'same_length_chars' or 'fixed_length_chars'..."
                )
        except ValueError as e:
            print(e)

        # check if the given domain is valid
        if self.custom_pipeline is None:
            domain_list = ["clinical", "finance", "legal"]
            try:
                if self.domain not in domain_list:
                    raise ValueError(
                        "You entered an invalid domain option. You can choose ether 'clinical', 'finance' or 'legal'. 'clinical' is used by default!"
                    )

            except ValueError as e:
                print(e)

        deid_pipeline = None

        if self.custom_pipeline is None:
            deid_pipeline = self.deid_with_pretrained_pipeline()

        elif self.custom_pipeline is not None:
            deid_pipeline = self.deid_with_custom_pipeline()

        return deid_pipeline

    def deid_with_custom_pipeline(self, pretrained_pipeline=None):
        """This function is used to deidentify the given data with custom pipeline."""

        df = pd.DataFrame(columns=["ID"])
        input_data_count = self.spark.read.csv(self.input_file_path, header=True, sep="\t").count()

        if len(self.fields)>1:
            self.multi_mode_file_path = list(self.fields.values())
        j = 0
        for i, mode in self.fields.items():

            if input_data_count == 3 or self.unnormalized_date or self.shift_days or len(self.fields)>1:
                input_text_col = "document.result"
                deidentification = (
                    DeIdentification()
                        .setInputCols([self.sentence, self.token, self.ner_chunk])
                        .setOutputCol("deidentified")
                        .setOutputAsDocument(True)
                )
            else:
                input_text_col = "sentence.result"
                deidentification = (
                    DeIdentification()
                        .setInputCols([self.sentence, self.token, self.ner_chunk])
                        .setOutputCol("deidentified")

                )

            if mode == "mask" and not self.unnormalized_date:
                if self.masking_policy in {"entity_labels", "same_length_chars", "fixed_length_chars"}:
                    deidentification = deidentification.setMode(mode).setMaskingPolicy(self.masking_policy)
                    if self.masking_policy == "fixed_length_chars":
                        deidentification = deidentification.setFixedMaskLength(self.fixed_mask_length)

            elif mode == "obfuscate" and not self.unnormalized_date and not self.shift_days:
                deidentification = deidentification.setMode(mode).setObfuscateDate(self.obfuscate_date)

                if self.obfuscate_ref_source == "faker":
                    deidentification = deidentification.setObfuscateRefSource(self.obfuscate_ref_source)
                elif self.obfuscate_ref_source in {"both", "file"}:
                    deidentification = deidentification.setObfuscateRefFile(
                        self.obfuscate_ref_file_path).setObfuscateRefSource(self.obfuscate_ref_source)
                elif self.age_group_obfuscation:
                    deidentification = deidentification.setObfuscateRefSource("faker").setAgeRanges(self.age_ranges)


            # --------Shifting days according to the ID column------------
            # --------DocumentHashCoder Should Be Feed By the USER-----

            elif (
                    self.shift_days is True
                    and mode == "obfuscate"
                    and self.unnormalized_date is False
            ):
                if pretrained_pipeline:
                    deidentification = (
                        DeIdentification()
                            .setInputCols([self.sentence, self.token, self.ner_chunk])
                            .setOutputCol("deidentified")
                            .setMode(mode)
                            .setObfuscateDate(self.obfuscate_date)
                            .setObfuscateRefSource("faker")
                            .setLanguage(self.language)
                            .setRegion(self.region)
                            .setUseShifDays(self.shift_days)
                            .setDays(self.number_of_days)
                            .setOutputAsDocument(True)
                    )
                else:
                    deidentification = (
                        DeIdentification()
                            .setInputCols(
                            [self.documenthashcoder_col_name, self.token, self.ner_chunk]
                        )
                            .setOutputCol("deidentified")
                            .setDateTag("DATE")
                            .setMode(mode)
                            .setObfuscateDate(self.obfuscate_date)
                            .setObfuscateRefSource("faker")
                            .setLanguage(self.language)
                            .setRegion(self.region)
                            .setUseShifDays(self.shift_days)
                            .setOutputAsDocument(True)
                    )

            # --------Unnormalized Date------------

            elif self.unnormalized_date:
                if pretrained_pipeline:
                    deidentification = (
                        DeIdentification()
                            .setInputCols([self.sentence, self.token, self.ner_chunk])
                            .setOutputCol("deidentified")
                            .setMode(mode)
                            .setObfuscateDate(self.obfuscate_date)
                            .setObfuscateRefSource("faker")
                            .setLanguage(self.language)
                            .setRegion(self.region)
                            .setUseShifDays(self.shift_days)
                            .setUnnormalizedDateMode(self.unnormalized_mode)
                            .setOutputAsDocument(True)
                    )
                else:
                    deidentification = (
                        DeIdentification()
                            .setInputCols([self.ner_chunk, self.token, self.documenthashcoder_col_name])
                            .setOutputCol("deidentified")
                            .setObfuscateDate(self.obfuscate_date)
                            .setDateTag(self.date_tag)
                            .setLanguage(self.language)
                            .setObfuscateRefSource("faker")
                            .setUseShifDays(True)
                            .setRegion(self.region)
                            .setUnnormalizedDateMode(self.unnormalized_mode)
                            .setOutputAsDocument(True)
                    )

                    if self.unnormalized_mode == "mask":
                        deidentification.setMode(mode)
                    elif self.unnormalized_mode == "obfuscate":
                        deidentification.setMode(self.unnormalized_mode)



            if self.multi_mode_file_path and type(self.multi_mode_file_path) is not list:
                deidentification.setObfuscateDate(True)
                deidentification.setSelectiveObfuscationModesPath(self.multi_mode_file_path)

            if type(self.multi_mode_file_path) is list and all(v.split(".")[-1] == "json" for v in self.multi_mode_file_path):
                if len(self.multi_mode_file_path)>1:
                    deidentification.setObfuscateDate(True)
                    deidentification.setSelectiveObfuscationModesPath(self.multi_mode_file_path[j])

            try:
                input_file_type = self.input_file_path.split(".")[-1]
                data = self.spark.read.option("multiLine", "true").option("quote", "\"").option("escape", "\"").csv(self.input_file_path, header=True, sep=self.separator)

                if input_file_type == "csv":
                    data = data

                elif input_file_type == "json":
                    data = self.spark.read.format(input_file_type).load(
                        self.input_file_path
                    )

            except Exception:
                raise Exception("You entered an invalid file path or file format...")

            data = data.withColumn(i, f.regexp_replace(i, '\n', ' '))

            try:
                print(f"Deidentification process of the '{i}' field has begun...")

                if pretrained_pipeline:
                    if i != "text":
                        pretrained_pipeline.model.stages[0].setInputCol(f"{i}")

                    elif i == "text":
                        pretrained_pipeline.model.stages[0].setInputCol(f"{i}")

                    # Creating Deid model
                    deid_pipeline = Pipeline(stages=[deidentification])
                    deid_model = deid_pipeline.fit(self.spark.createDataFrame([[""]]).toDF("text"))
                    deid_pipeline = PipelineModel(
                        stages=[pretrained_pipeline, deid_model]
                    )
                    result = deid_pipeline.transform(data)
                else:
                    if i != "text":
                        self.custom_pipeline.stages[0].setInputCol(f"{i}")

                    elif i == "text":
                        self.custom_pipeline.stages[0].setInputCol(f"{i}")
                    deid_pipeline = Pipeline(
                        stages=[self.custom_pipeline, deidentification]
                    )
                    model = deid_pipeline.fit(data)
                    result = model.transform(data)



                result = result.withColumn("ID", monotonically_increasing_id())
                output_df = result.selectExpr("ID", f"{input_text_col} as {i}", f"deidentified.result as {i}_deidentified").toPandas()

                df = pd.merge(df, output_df, on="ID", how="outer")
                df.reset_index(drop=True, inplace=True)

                print(f"Deidentification process of the '{i}' field was completed...")
            except Exception:
                raise Exception(
                    "You entered either an invalid field name or wrong separator for input csv file..."
                )
            j += 1

        input_file_type = self.input_file_path.split(".")[-1]
        if input_file_type == "csv":
            df.to_csv(f"{self.output_file_path}", index=False)
            print(
                f"Deidentifcation successfully completed and the results saved as '{self.output_file_path}' !"
            )

        elif input_file_type == "json":
            df.to_json(f"{self.output_file_path}", orient="records")
            print(
                f"Deidentifcation successfully completed and the results saved as '{self.output_file_path}' !"
            )

        return_df = self.spark.createDataFrame(df)

        return return_df

    def deid_with_pretrained_pipeline(self):
        """Deidentification with pretrained pipeline"""

        if self.domain == "finance":
            pretrained_pipeline = PretrainedPipeline("finpipe_deid", "en", "finance/models")
            pretrained_pipeline.model.stages = pretrained_pipeline.model.stages[:-4]
            pretrained_pipeline.model.stages[-1].setOutputCol("ner_chunk")
        elif self.domain == "legal":
            pretrained_pipeline = PretrainedPipeline("legpipe_deid", "en", "legal/models")
        else:
            pretrained_pipeline = PretrainedPipeline("ner_deid_subentity_augmented_i2b2_pipeline", "en",
                                                     "clinical/models")

        return self.deid_with_custom_pipeline(pretrained_pipeline)
