from sparknlp_jsl.common import *
from sparknlp.annotator.embeddings.bert_sentence_embeddings import BertSentenceEmbeddings

class ChunkKeyPhraseExtraction(BertSentenceEmbeddings, HasEngine):
    """Extracts key phrases from texts.

    `ChunkKeyPhraseExtraction` uses `BertSentenceEmbeddings` to determine the most
    relevant key phrases describing a text with the use of two approaches:
    - By using cosine similarities between the embedding representation of the chunks
    and the embedding representation of the corresponding sentences/documents.
    - By using the Maximal Marginal Relevance (MMR) algorithm (set with the
    `setDivergence` method) to determine the most relevant key phrases.

    If the `selectMostDifferent` parameter is set, return the key phrases that are the
    most different from each other (avoid too similar key phrases).

    The model compares the chunks against the corresponding sentences/documents and selects
    the chunks which are most representative of the broader text context
    (i.e., the document or the sentence they belong to). This allows, for example, to
    obtain a brief understanding of a document by selecting the most relevant
    phrases.

    The input to the model consists of chunk annotations and sentence or
    document annotation. The input chunks can be generated in various ways:
    - Using `NGramGenerator`, which allows to obtain ranked n-gram chunks from the text (can be
    used to identify new entities).
    - Using `YakeKeywordExtractor`, allowing to rank the keywords extracted using the
    YAKE algorithm.
    - Using `TextMatcher`, which allows to rank the desired chunks from the annotator.
    - Using `NerConverter`, which allows to extract ranked named entities (which entities
    are the most relevant in the sentence/document).

    The model operates either at sentence (selecting the most descriptive chunks from
    the sentence they belong to) or at document level. In the latter case, the key
    phrases are selected to represent all the input document annotations.

    ====================== ======================
    Input Annotation types Output Annotation type
    ====================== ======================
    ``DOCUMENT, CHUNK``    ``CHUNK``
    ====================== ======================

    Parameters
    ----------

    topN
        The number of key phrases to select. Default: 3.
    selectMostDifferent
        Pre-select `topN * 2` key phrases and out of those select the `topN` that are
        the most different from each other.
        This parameter should not be used in conjunction with `divergence` as they aim
        to achieve the same goal, but in different ways.
        Default: False.
    divergence
        The divergence value determines how different from each the extracted key phrases are.
        Possible values are within the interval [0, 1]. The higher the value is, the more
        divergence is enforced. A value of 0 means the key phrases are not compared to each
        other (no divergence is ensured) and their relevance is determined solely by
        their similarity to the document.
        This parameter should not be used if selectMostDifferent is set to True, as the two
        parameters aim to achieve the same goal in different ways.
        The default value is 0, meaning that the there is no constraint on the order of the
        extracted key phrases.
        The divergence is calculated using the Maximal Marginal Relevance measure.
        Default: 0.0.
    documentLevelProcessing
        A flag indicating whether to extract key phrases from the document level,
        i.e. from all the sentences available at a given row, rather than from the
        particular sentences the chunks refer to. Default: True.
    concatenateSentences
        A flag indicating whether to concatenate all input document/sentence
        annotations before computing their embedding. This parameter is only used
        if `documentLevelProcessing` is set to `True`.
        If `concatenateSentences` is set to `True`, then the model will concatenate
        the document/sentence input annotations and compute a single embedding.
        If it is set to `False`, then the model will compute the embedding of each
        sentence separately, and average the resulting embedding vectors in the end.
        Default: True.
    dropPunctuation
        This parameter indicates whether to remove punctuation marks from the input
        chunks. Chunks coming from NER models are not affected.
        Default: True.

    Examples
    --------

    >>> documenter = sparknlp.DocumentAssembler() \
    ...     .setInputCol("text") \
    ...     .setOutputCol("document")
    ...
    >>> sentencer = sparknlp.annotators.SentenceDetector() \
    ...     .setInputCols(["document"])\
    ...     .setOutputCol("sentences")
    ...
    >>> tokenizer = sparknlp.annotators.Tokenizer() \
    ...     .setInputCols(["document"]) \
    ...     .setOutputCol("tokens") \
    ...
    >>>  embeddings = sparknlp.annotators.WordEmbeddingsModel() \
    ...     .pretrained("embeddings_clinical", "en", "clinical/models") \
    ...     .setInputCols(["document", "tokens"]) \
    ...     .setOutputCol("embeddings")
    ...
    >>> ner_tagger = MedicalNerModel() \
    ...     .pretrained("ner_jsl_slim", "en", "clinical/models") \
    ...     .setInputCols(["sentences", "tokens", "embeddings"]) \
    ...     .setOutputCol("ner_tags")
    ...
    >>> ner_converter = NerConverter()\
    ...     .setInputCols("sentences", "tokens", "ner_tags")\
    ...     .setOutputCol("ner_chunks")
    ...
    >>> key_phrase_extractor = ChunkKeyPhraseExtraction\
    ...     .pretrained()\
    ...     .setTopN(1)\
    ...     .setDocumentLevelProcessing(False)\
    ...     .setDivergence(0.4)\
    ...     .setInputCols(["sentences", "ner_chunks"])\
    ...     .setOutputCol("ner_chunk_key_phrases")
    ...
    >>> pipeline = sparknlp.base.Pipeline() \
    ...     .setStages([documenter, sentencer, tokenizer, embeddings, ner_tagger, ner_converter, key_phrase_extractor])
    ...
    >>> data = spark.createDataFrame([["Her Diabetes has become type 2 in the last year with her Diabetes.He complains of swelling in his right forearm."]]).toDF("text")
    >>> results = pipeline.fit(data).transform(data)
    >>> results\
    ...     .selectExpr("explode(ner_chunk_key_phrases) AS key_phrase")\
    ...     .selectExpr(
    ...         "key_phrase.result",
    ...         "key_phrase.metadata.entity",
    ...         "key_phrase.metadata.DocumentSimilarity",
    ...         "key_phrase.metadata.MMRScore")\
    ...     .show(truncate=False)

    +-----------------------------+------------------+-------------------+
    |result                       |DocumentSimilarity|MMRScore           |
    +-----------------------------+------------------+-------------------+
    |gestational diabetes mellitus|0.7391447825527298|0.44348688715422274|
    |28-year-old                  |0.4366776288430703|0.13577881610104517|
    |type two diabetes mellitus   |0.7323921930094919|0.085800103824974  |
    +-----------------------------+------------------+-------------------+

    """
    inputAnnotatorTypes = [AnnotatorType.DOCUMENT, AnnotatorType.CHUNK]
    outputAnnotatorType = AnnotatorType.CHUNK

    name = "ChunkKeyPhraseExtraction"

    topN = Param(Params._dummy(),
                 "topN",
                 "Number of key phrases to extract, ordered by their score",
                 typeConverter=TypeConverters.toInt
                 )

    def setTopN(self, value: int):
        """Set the number of key phrases to extract. The default value is 3.

        Parameters
        ----------
        value : int
           Number of key phrases to extract.
        """
        return self._set(topN=value)

    divergence = Param(Params._dummy(),
                       "divergence",
                       "The divergence value determines how different from each the extracted key phrases are. "
                       "The value must be in the the interval [0, 1]. The higher the value is, "
                       "the more divergence is enforced.  The default value is 0.2.",
                       typeConverter=TypeConverters.toFloat
                       )

    def setDivergence(self, value:float):
        """Sets the divergence value.

        The divergence value determines how different from each the extracted key phrases are.
        The value must be in the the interval [0, 1].
        The higher the value is, the more divergence is enforced.
        The default value is 0.0.

        Parameters
        ----------
        value : float
           Divergence value between 0.0 and 1.0.
        """
        return self._set(divergence=value)

    selectMostDifferent = Param(Params._dummy(),
                                "selectMostDifferent",
                                "Find the topN * 2 key phrases and then select topN of them, such as that they are the "
                                "most different from each other",
                                typeConverter=TypeConverters.toBoolean
                                )

    def setSelectMostDifferent(self, value:bool):
        """Sets the selectMostDifferent parameter.

        If set to True, the model returns the top N key phrases which are the
        most different from each other. If set to False, the model returns the
        top N key phrases which have the highest score.

        The default value is `False`.

        Parameters
        ----------
        value : bool
           whether to select the most different key phrases or not.
        """
        return self._set(selectMostDifferent=value)

    documentLevelProcessing = Param(Params._dummy(),
                                    "documentLevelProcessing",
                                    "Let the model extract key phrase at the document or at the sentence level",
                                    typeConverter=TypeConverters.toBoolean
                                    )

    def setDocumentLevelProcessing(self, value:bool):
        """Sets the documentLevelProcessing parameter.

        If set to True, the model will extract key phrases from the whole
        document. If set to False, the model will extract key phrases from each
        sentence separately. The default value is `True`.

        Parameters
        ----------
        value : bool
           Whether to extract key phrases from the whole document(all sentences).
        """
        return self._set(documentLevelProcessing=value)

    concatenateSentences = Param(Params._dummy(),
                                 "concatenateSentences",
                                 "Concatenate input sentence annotations before computing their embedding.",
                                 typeConverter=TypeConverters.toBoolean
                                 )

    def setConcatenateSentences(self, value:bool):
        """Sets the concatenateSentences parameter.

        If set to True, the model will concatenate the input sentence annotations
        before computing their embedding. If set to False, the model will compute
        the embedding of each sentence separately and then average them.
        The default value is `True`.

        Parameters
        ----------
        value : bool
           Whether to concatenate the input sentence/document annotations in order
           to compute the embedding of the whole document.
        """
        return self._set(concatenateSentences=value)

    dropPunctuation = Param(Params._dummy(),
                            "dropPunctuation",
                            "Remove punctuation marks from input chunks.",
                            typeConverter=TypeConverters.toBoolean
                            )

    def setDropPunctuation(self, value:bool):
        """Sets the dropPunctuation parameter.

        This parameter determines whether to remove punctuation marks from the input chunks.
        Chunks coming from NER models are not affected.
        The default value is `True`.

        Parameters
        ----------
        value : bool
           Whether to remove punctuation marks from input chunks.
        """
        return self._set(dropPunctuation=value)

    @keyword_only
    def __init__(self, classname="com.johnsnowlabs.nlp.embeddings.ChunkKeyPhraseExtraction", java_model=None):
        super(ChunkKeyPhraseExtraction, self).__init__(
            classname=classname,
            java_model=java_model
        )
        self._setDefault(
            dimension=768,
            batchSize=8,
            maxSentenceLength=128,
            caseSensitive=False,
            divergence=0.0,
            documentLevelProcessing=True,
            topN=3,
            selectMostDifferent=False,
            concatenateSentences=True,
            dropPunctuation=True
        )

    @staticmethod
    def pretrained(name="sbert_jsl_medium_uncased", lang="en", remote_loc="clinical/models"):
        """Downloads and loads a pretrained model.

        Parameters
        ----------
        name : str, optional
            Name of the pretrained model.
        lang : str, optional
            Language of the pretrained model, by default "en"
        remote_loc : str, optional
            Optional remote address of the resource, by default "clinical/models". Will use
            Spark NLPs repositories otherwise.

        Returns
        -------
        ChunkKeyPhraseExtraction
            The restored model
        """
        from sparknlp_jsl.pretrained import InternalResourceDownloader
        return InternalResourceDownloader.downloadModel(ChunkKeyPhraseExtraction, name, lang, remote_loc,
                                                        j_dwn='InternalsPythonResourceDownloader')