from sparknlp_jsl.common import AnnotatorProperties
from sparknlp_jsl.annotator import *


class Mapper2Chunk(AnnotatorTransformer, AnnotatorProperties):
    """This annotator converts 'LABELED_DEPENDENCY' type annotations coming from [[ChunkMapper]] into 'CHUNK' type to create new chunk-type column,
       compatible with annotators that use chunk type as input.


    ====================== ======================
    Input Annotation types Output Annotation type
    ====================== ======================
    ``LABELED_DEPENDENCY``       ``CHUNK``
    ====================== ======================

    Parameters
    ----------

    Examples
    --------
    >>> import sparknlp
    >>> from sparknlp.base import *
    >>> from sparknlp_jsl.common import *
    >>> from sparknlp.annotator import *
    >>> from sparknlp.training import *
    >>> from pyspark.ml import Pipeline

    >>> # Sample data
    >>> text = "Patient resting in bed. Patient given azithromycin without any difficulty. Patient denies nausea at this time. zofran declined. Patient is also having intermittent sweating"
    >>> data = spark.createDataFrame([[text]]).toDF("text")

    >>> # Define the Spark NLP pipeline stages
    >>> documentAssembler = DocumentAssembler() \
    >>>     .setInputCol("text") \
    >>>     .setOutputCol("document")

    >>> sentenceDetector = SentenceDetector() \
    >>>     .setInputCols(["document"]) \
    >>>     .setOutputCol("sentence")

    >>> tokenizer = Tokenizer() \
    >>>     .setInputCols(["sentence"]) \
    >>>     .setOutputCol("token")

    >>> word_embeddings = WordEmbeddingsModel.pretrained("embeddings_clinical", "en", "clinical/models") \
    >>>     .setInputCols(["sentence", "token"]) \
    >>>     .setOutputCol("embeddings")

    >>> clinical_ner = MedicalNerModel.pretrained("ner_jsl", "en", "clinical/models") \
    >>>     .setInputCols(["sentence", "token", "embeddings"]) \
    >>>     .setOutputCol("ner")

    >>> ner_converter = NerConverterInternal() \
    >>>     .setInputCols(["sentence", "token", "ner"]) \
    >>>     .setOutputCol("ner_chunk")

    >>> chunkMapper = ChunkMapperModel.pretrained("drug_action_treatment_mapper", "en", "clinical/models") \
    >>>     .setInputCols(["ner_chunk"]) \
    >>>     .setOutputCol("relations") \
    >>>     .setRels(["action"])

    >>> mapper2chunk = Mapper2Chunk() \
    >>>     .setInputCols(["relations"]) \
    >>>     .setOutputCol("chunk") \
    >>>     .setFilterNoneValues(True)

    >>> # Build the pipeline
    >>> pipeline = Pipeline(stages=[
    >>>     documentAssembler,
    >>>     sentenceDetector,
    >>>     tokenizer,
    >>>     word_embeddings,
    >>>     clinical_ner,
    >>>     ner_converter,
    >>>     chunkMapper,
    >>>     mapper2chunk
    >>> ]).fit(data)

    >>> # Transform the data using the pipeline
    >>> result = pipeline.transform(data)


    >>> result.selectExpr("chunk.result", "chunk.annotatorType").show(truncate=False)

        +--------------------------+--------------+
        |result                    |annotatorType |
        +--------------------------+--------------+
        |[bactericidal, antiemetic]|[chunk, chunk]|
        +--------------------------+--------------+
    """

    inputAnnotatorTypes = [AnnotatorType.LABELED_DEPENDENCY]
    outputAnnotatorType = AnnotatorType.CHUNK

    name = "Mapper2Chunk"

    filterNoneValues = Param(Params._dummy(), "filterNoneValues", "whether to filter 'NONE' values. Default is false.",
                             typeConverter=TypeConverters.toBoolean)

    def setFilterNoneValues(self, value):
        """ Whether to filter 'NONE' values. Default is false.

        Parameters
        ----------
        value : bool
            Whether to filter 'NONE' values.
        """
        return self._set(filterNoneValues=value)

    @keyword_only
    def __init__(self):
        super(Mapper2Chunk, self).__init__(classname="com.johnsnowlabs.nlp.annotators.chunker.Mapper2Chunk")

    @keyword_only
    def setParams(self):
        kwargs = self._input_kwargs
        return self._set(**kwargs)
