from sparknlp_jsl.common import *

class ChunkSentenceSplitter(AnnotatorModelInternal):
    """
    An annotator that splits a document into sentences based on provided chunks.
    The first piece of the document is treated as a header, and subsequent chunks are labeled with their associated entities.

    This annotator is particularly useful when identifying titles and subtitles using Named Entity Recognition (NER),
    followed by a paragraph-level split.

    ====================== ======================
    Input Annotation types Output Annotation type
    ====================== ======================
    ``DOCUMENT, CHUNK``    ``DOCUMENT``
    ====================== ======================

    Parameters
    ----------
    groupBySentences: bool
        Whether to split a document into paragraphs by grouping chunks by sentences.
        If set to False, it assumes a single document annotation for all chunks.
        Set to True if you want to group chunks by sentences, and the input column of your chunk annotator is generated by a sentence detector.
        Default: True
    insertChunk: bool
        Whether to include the chunk in the resulting sentences or not.
        When `insertChunk` is set to True, the chunk will be added to the generated sentences.
        If set to False, the chunk will be omitted from the sentences.
        Default: True
    defaultEntity: str
        Defining the default name for the entity that represents content between the beginning of the document and the first chunk.
        Default: 'introduction'
        
    Examples
    --------
    >>> document = DocumentAssembler().setInputCol("text").setOutputCol("document")
    >>> regexMatcher = RegexMatcher().setExternalRules("../src/test/resources/chunker/title_regex.txt", ",") \\
    ...     .setInputCols("document") \\
    ...     .setOutputCol("chunks") \\
    >>> chunkSentenceSplitter = ChunkSentenceSplitter().setInputCols("chunks","document").setOutputCol("paragraphs")
    >>> pipeline = Pipeline().setStages([documentAssembler,regexMatcher,chunkSentenceSplitter])
    >>> result = pipeline.fit(data).transform(data).select("paragraphs")
    >>> result.show()

    """
    inputAnnotatorTypes = [AnnotatorType.DOCUMENT, AnnotatorType.CHUNK]
    outputAnnotatorType = AnnotatorType.DOCUMENT

    groupBySentences = Param(Params._dummy(), "groupBySentences",
                             "whether to split a document into paragraphs by grouping chunks by sentences."+
                             "If set to False, it assumes a single document annotation for all chunks."+
                             "Set to True if you want to group chunks by sentences, and the input column of your chunk annotator is generated by a sentence detector.",
                             TypeConverters.toBoolean)

    insertChunk = Param(Params._dummy(), "insertChunk", "Whether to insert the chunk in the paragraph or not",
                        TypeConverters.toBoolean)

    defaultEntity = Param(Params._dummy(), "defaultEntity",
                          "Add the default name for the entity that is between the init of the document and the first chunk",
                          TypeConverters.toString)

    name = "ChunkSentenceSplitter"

    def setGroupBySentences(self, value):
        """Sets the groupBySentences property, which determines whether to split a document into paragraphs by grouping chunks by sentences.
        If set to False, it assumes a single document annotation for all chunks.
        Set to True if you want to group chunks by sentences, and the input column of your chunk annotator is generated by a sentence detector.
        Default: True

        Parameters
        ----------
        value : Boolean
           Whether to split a document into paragraphs by grouping chunks by sentence. Default: True
        """
        return self._set(groupBySentences=value)

    def setInsertChunk(self, value):
        """Sets the value for the `insertChunk` parameter, determining whether to include the chunk in the resulting sentences or not.
        When `insertChunk` is set to True, the chunk will be added to the generated sentences.
        If set to False, the chunk will be omitted from the sentences.

        Parameters
        ----------
        value : Boolean
           Whether to insert the chunk in the sentences or not. Default: True
        """
        return self._set(insertChunk=value)

    def setDefaultEntity(self, value):
        """Sets `defaultEntity`, defining the default name for the entity that represents content between the beginning of the document and the first chunk.

        Parameters
        ----------
        value : str
           Defining the default name for the entity that represents content between the beginning of the document and the first chunk.
        """
        return self._set(defaultEntity=value)

    def __init__(self, classname="com.johnsnowlabs.nlp.annotators.chunker.ChunkSentenceSplitter", java_model=None):
        super(ChunkSentenceSplitter, self).__init__(
            classname=classname,
            java_model=java_model
        )