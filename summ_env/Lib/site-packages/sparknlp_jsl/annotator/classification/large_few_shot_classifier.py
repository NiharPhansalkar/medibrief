from sparknlp_jsl.common import *
from sparknlp.common import *

class LargeFewShotClassifierModel(AnnotatorModelInternal,
                                  HasCaseSensitiveProperties,
                                  HasBatchedAnnotate,
                                  HasMaxSentenceLengthLimit):
    """
     LargeFewShotClassifierModel annotator can run large (LLMS based) few shot classifiers based on the SetFit approach.

     ==========================================  ======================
     Input Annotation types                      Output Annotation type
     ==========================================  ======================
     ``DOCUMENT``                                   ``CATEGORY``
     ==========================================  ======================

     Parameters
     ----------
     batchSize
         Batch size
     caseSensitive
         Whether the classifier is senstivie to text casing
     maxSentenceLength
         The maximum length of the input text
     Examples
     --------
     >>> document_assembler = sparknlp.DocumentAssembler() \
     ...     .setInputCol("text") \
     ...     .setOutputCol("document")
    >>> large_few_shot_classifier = LargeFewShotClassifierModel().pretrained()\
     ...     .setInputCols("document")\
     ...     .setOutputCol("label")
     >>> data = spark.createDataFrame(
     ...     [["I felt a bit drowsy and had blurred vision after taking Aspirin."]]
     ...     ).toDF("text")
     >>> results = sparknlp.base.Pipeline() \
     ...     .setStages([document_assembler, large_few_shot_classifier]) \
     ...     .fit(data) \
     ...     .transform(data) \
     >>> results\
     ...     .selectExpr("explode(label) as label")\
     ...     .selectExpr("label.result", "label.metadata.confidence")\
     ...     .show()

        +------+----------+
        |result|confidence|
        +------+----------+
        |   ADE| 0.9672883|
        +------+----------+
     """

    inputAnnotatorTypes = [AnnotatorType.DOCUMENT]
    outputAnnotatorType = AnnotatorType.CATEGORY

    name = "LargeFewShotClassifierModel"

    modelArchitecture = Param(Params._dummy(), "modelArchitecture", "Architecture of the sentence embeddings model.",
                           typeConverter=TypeConverters.toString)
    hasDifferentiableHead = Param(Params._dummy(), "hasDifferentiableHead", "The classifier is differentiable.",
                                 typeConverter=TypeConverters.toBoolean)

    def getClasses(self):
        """
        Returns labels used to train this model
        """
        return self._call_java("getClasses")

    def __init__(self, classname="com.johnsnowlabs.nlp.annotators.classification.LargeFewShotClassifierModel",
                 java_model=None):
        super(LargeFewShotClassifierModel, self).__init__(
            classname=classname,
            java_model=java_model
        )

    @staticmethod
    def loadSavedModel(folder, spark_session, model_architecture, has_differentiable_head=False):
        """Loads a locally saved model.

        Parameters
        ----------
        folder : str
            Folder of the saved model
        spark_session : pyspark.sql.SparkSession
            The current SparkSession
        model_architecture: str
            The model architecture of the underlying sentence embeddings model, e.g. MPNet or Bert
        has_differentiable_head: bool
            A flag indicating whether the classifier is differentiable

        Returns
        -------
        LargeFewShotClassifierModel
            The restored model
        """
        from sparknlp_jsl.internal import _LargeFewShotClassifierModelLoader
        jModel = _LargeFewShotClassifierModelLoader(folder,
                                                    spark_session._jsparkSession,
                                                    model_architecture,
                                                    has_differentiable_head)._java_obj
        return LargeFewShotClassifierModel(java_model=jModel)

    @staticmethod
    def pretrained(name="large_fewshot_classifier_ade", lang="en", remote_loc="clinical/models"):
        """Downloads and loads a pretrained model.

        Parameters
        ----------
        name : str, optional
            Name of the pretrained model, by default "large_fewshot_classifier_ade".
        lang : str, optional
            Language of the pretrained model, by default "en"
        remote_loc : str, optional
            Optional remote address of the resource, by default None. Will use
            Spark NLPs repositories otherwise.

        Returns
        -------
        LargeFewShotClassifierModel
            The restored model
        """
        from sparknlp_jsl.pretrained import InternalResourceDownloader
        return InternalResourceDownloader.downloadModel(LargeFewShotClassifierModel, name, lang, remote_loc,
                                                        j_dwn='InternalsPythonResourceDownloader')