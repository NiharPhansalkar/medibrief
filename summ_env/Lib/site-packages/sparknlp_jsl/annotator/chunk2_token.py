from sparknlp_jsl.common import *


class Chunk2Token(AnnotatorModelInternal):
    """Converts ``CHUNK`` type annotations into ``TOKEN`` type

        ====================== ======================
        Input Annotation types Output Annotation type
        ====================== ======================
        ``CHUNK``              ``TOKEN``
        ====================== ======================


        Examples
        --------
        >>> import sparknlp
        >>> from sparknlp.base import *
        >>> from sparknlp.annotator import *
        >>> from pyspark.ml import Pipeline
        >>> documentAssembler = DocumentAssembler().setInputCol("text").setOutputCol("document")
        >>> chunkAssembler = sentenceDetector = SentenceDetector().setInputCols("document").setOutputCol("sentence")
        >>> tokenizer = Tokenizer().setInputCols("sentence").setOutputCol("token")
        >>> nGramGenerator = NGramGenerator().setInputCols("token").setOutputCol("ngrams") \\
        ...     .setDelimiter("_").setN(2).setEnableCumulative(False)
        >>> chunk2Token = Chunk2Token().setInputCols("ngrams").setOutputCol("ngram_tokens")
        >>> data = spark.createDataFrame([["A 63-year-old man presents to the hospital."]]).toDF("text")
        >>> pipeline = Pipeline() \\
        ...     .setStages([documentAssembler, chunkAssembler, tokenizer, nGramGenerator, chunk2Token]).fit(data)
        >>> result = pipeline.transform(data)
        >>> result.selectExpr("ngram_tokens").show(truncate=False)
        +----------------------------------------------------------------+
        |result                                                          |
        +----------------------------------------------------------------+
        |{token, 0, 12, A_63-year-old, {sentence -> 0, chunk -> 0}, []}  |
        |{token, 2, 16, 63-year-old_man, {sentence -> 0, chunk -> 1}, []}|
        |{token, 14, 25, man_presents, {sentence -> 0, chunk -> 2}, []}  |
        |{token, 18, 28, presents_to, {sentence -> 0, chunk -> 3}, []}   |
        |{token, 27, 32, to_the, {sentence -> 0, chunk -> 4}, []}        |
        |{token, 30, 41, the_hospital, {sentence -> 0, chunk -> 5}, []}  |
        |{token, 34, 42, hospital_., {sentence -> 0, chunk -> 6}, []}    |
        +----------------------------------------------------------------+

    """
    name = "Chunk2Token"
    inputAnnotatorTypes = [AnnotatorType.CHUNK]
    outputAnnotatorType = AnnotatorType.TOKEN

    def __init__(self, classname="com.johnsnowlabs.nlp.annotators.Chunk2Token", java_model=None):
        super(Chunk2Token, self).__init__(
            classname=classname,
            java_model=java_model
        )
