from sparknlp_jsl.common import *
from sparknlp.internal import AnnotatorTransformer

class FewShotAssertionSentenceConverter(AnnotatorTransformer):
    """




    ==============================  ======================
    Input Annotation types          Output Annotation type
    ==============================  ======================
    ``TOKEN``                       ``CHUNK``
    ==============================  ======================

    Parameters
    ----------

    """
    name = 'FewShotAssertionSentenceConverter'

    inputAnnotatorTypes = [AnnotatorType.DOCUMENT, AnnotatorType.CHUNK]
    outputAnnotatorType = AnnotatorType.DOCUMENT

    inputCols = Param(Params._dummy(), "inputCols",
                      "input annotations",
                      typeConverter=TypeConverters.toListString)

    outputCol = Param(Params._dummy(), "outputCol",
                       "output finished annotation col",
                       typeConverter=TypeConverters.toString)

    scopeWindow = Param(Params._dummy(), "scopeWindow", "The scope window of the assertion expression",
                        TypeConverters.toListInt)

    def setScopeWindow(self, value:list):
        """Sets the scope of the window of the assertion expression.

        Parameters
        ----------
        value : list
            Left and right offset if the scope window. Offsets must be
            non-negative values.
        """
        assert (type(value) is list)
        assert (len(value) == 2)

        return self._set(scopeWindow=value)

    @keyword_only
    def __init__(self):
        super(FewShotAssertionSentenceConverter, self)\
            .__init__(classname="com.johnsnowlabs.nlp.annotators.assertion.FewShotAssertionSentenceConverter")
        self._setDefault(scopeWindow=[0, 0])

    @keyword_only
    def setParams(self):
        kwargs = self._input_kwargs
        return self._set(**kwargs)
