from sparknlp_jsl.annotator.handle_exception_params import HandleExceptionParams
from sparknlp_jsl.common import *
from sparknlp_jsl.annotator.generic_classifier.generic_classifier import GenericClassifierApproach
from sparknlp_jsl.annotator.generic_classifier.generic_classifier import GenericClassifierModel


class RelationExtractionApproach(GenericClassifierApproach, HandleExceptionParams):
    """Trains a TensorFlow model for relation extraction.

    For pretrained models, see the documentation of `RelationExtractionModel`.

    To train a custom relation extraction model, you need to first create
    a Tensorflow graph using either the `TfGraphBuilder` annotator or
    the `tf_graph` module. Then, set the path to the Tensorflow graph
    using the method `.setModelFile("path/to/tensorflow_graph.pb")`.

    If the parameter `relationDirectionCol` is set, the model will be
    trained using the direction information (see the parameter decription
    for details). Otherwise, the model won't have direction between the
    relation of the entities.

    After training a model (using the `.fit()` method), the resulting object is
    of class `RelationExtractionModel`.

    ===========================================  ======================
    Input Annotation types                       Output Annotation type
    ===========================================  ======================
    ``WORD_EMBEDDINGS, POS, CHUNK, DEPENDENCY``  ``CATEGORY``
    ===========================================  ======================

    Parameters
    ----------
    fromEntityBeginCol
        From Entity Begining Column
    fromEntityEndCol
        From Entity End Column
    fromEntityLabelCol
        From Entity Label Column
    toEntityBeginCol
        To Entity Begining Column
    toEntityEndCol
        To Entity End Column
    toEntityLabelCol
        To Entity Label Column
    relationDirectionCol
        Relation direction column which contains the information of the
        relation between the "from entity" and the "to entity".
        Possible values in this column are:
        - "leftwards": the relation arguments are ordered from right to left (<-) in the text.
        - "rightwards": the relation arguments are ordered from left to right (->) in the text.
        - "both": Order doesn't matter, the relation is symmetric (<->).
        If this parameter is not set, the model will not have direction
        between the relation of the entities.
    pretrainedModelPath
        Path to an already trained MedicalNerModel, which is used as a starting point
        for training the new model. The path can be a local file path,
        a distributed file path (HDFS, DBFS), or a cloud storage (S3).
    directionSensitive
        Specify direction sensitivity in processing relation pairs Default is 'false'.
    filterByTokenDistance
        Filtering criterion based on number of token between entities (Default: 0).
    scopeWindow
        The scope window of the feature generation. Default :[-1, -1].




    Examples
    --------

    >>> import sparknlp
    >>> from sparknlp.base import *
    >>> from sparknlp_jsl.common import *
    >>> from sparknlp.annotator import *
    >>> from sparknlp.training import *
    >>> import sparknlp_jsl
    >>> from sparknlp_jsl.base import *
    >>> from sparknlp_jsl.annotator import *
    >>> from pyspark.ml import Pipeline
    >>> documentAssembler = DocumentAssembler() \\
    ...   .setInputCol("text") \\
    ...   .setOutputCol("document")
    ...
    >>> tokenizer = Tokenizer() \\
    ...   .setInputCols(["document"]) \\
    ...   .setOutputCol("tokens")
    ...
    >>> embedder = WordEmbeddingsModel \\
    ...   .pretrained("embeddings_clinical", "en", "clinical/models") \\
    ...   .setInputCols(["document", "tokens"]) \\
    ...   .setOutputCol("embeddings")
    ...
    >>> posTagger = PerceptronModel \\
    ...   .pretrained("pos_clinical", "en", "clinical/models") \\
    ...   .setInputCols(["document", "tokens"]) \\
    ...   .setOutputCol("posTags")
    ...
    >>> nerTagger = MedicalNerModel \\
    ...   .pretrained("ner_events_clinical", "en", "clinical/models") \\
    ...   .setInputCols(["document", "tokens", "embeddings"]) \\
    ...   .setOutputCol("ner_tags")
    ...
    >>> nerConverter = NerConverter() \\
    ...   .setInputCols(["document", "tokens", "ner_tags"]) \\
    ...   .setOutputCol("nerChunks")
    ...
    >>> depencyParser = DependencyParserModel \\
    ...   .pretrained("dependency_conllu", "en") \\
    ...   .setInputCols(["document", "posTags", "tokens"]) \\
    ...   .setOutputCol("dependencies")
    ...
    >>> re = RelationExtractionApproach() \\
    ...   .setInputCols(["embeddings", "posTags", "train_ner_chunks", "dependencies"]) \\
    ...   .setOutputCol("relations_t") \\
    ...   .setLabelColumn("target_rel") \\
    ...   .setEpochsNumber(300) \\
    ...   .setBatchSize(200) \\
    ...   .setLearningRate(0.001) \\
    ...   .setModelFile("path/to/graph_file.pb") \\
    ...   .setFixImbalance(True) \\
    ...   .setValidationSplit(0.05) \\
    ...   .setFromEntity("from_begin", "from_end", "from_label") \\
    ...   .setToEntity("to_begin", "to_end", "to_label")
    ...
    >>> pipeline = Pipeline(stages=[
    ...     documentAssembler,
    ...     tokenizer,
    ...     embedder,
    ...     posTagger,
    ...     nerTagger,
    ...     nerConverter,
    ...     depencyParser,
    ...     re])

    >>> model = pipeline.fit(trainData)

    """
    inputAnnotatorTypes = [AnnotatorType.WORD_EMBEDDINGS, AnnotatorType.POS, AnnotatorType.CHUNK, AnnotatorType.DEPENDENCY]
    outputAnnotatorType = AnnotatorType.CATEGORY

    name = "RelationExtractionApproach"

    fromEntityBeginCol = Param(Params._dummy(), "fromEntityBeginCol", "From Entity Begining Column",
                               TypeConverters.toString)
    fromEntityEndCol = Param(Params._dummy(), "fromEntityEndCol", "From Entity End Column", TypeConverters.toString)
    fromEntityLabelCol = Param(Params._dummy(), "fromEntityLabelCol", "From Entity Label Column",
                               TypeConverters.toString)

    toEntityBeginCol = Param(Params._dummy(), "toEntityBeginCol", "To Entity Begining Column", TypeConverters.toString)
    toEntityEndCol = Param(Params._dummy(), "toEntityEndCol", "To Entity End Column", TypeConverters.toString)
    toEntityLabelCol = Param(Params._dummy(), "toEntityLabelCol", "To Entity Label Column", TypeConverters.toString)
    relationDirectionCol = Param(Params._dummy(), "relationDirectionCol", "Relation direction column", TypeConverters.toString)

    customLabels = Param(Params._dummy(), "customLabels",
                         "Custom relation labels",
                         TypeConverters.identity)

    pretrainedModelPath = Param(Params._dummy(), "pretrainedModelPath",
                                "Path to an already trained RelationExtractionModel, which is used as a starting point for training the new model.",
                                TypeConverters.toString)

    overrideExistingLabels = Param(Params._dummy(), "overrideExistingLabels",
                                 "Whether to override already learned labels when using a pretrained model to initialize the new model. Default is 'true'.",
                                 TypeConverters.toBoolean)

    maxSyntacticDistance = Param(Params._dummy(), "maxSyntacticDistance",
                                 "Maximal syntactic distance, as threshold (Default: 0)",
                                 TypeConverters.toInt)
    directionSensitive = Param(Params._dummy(), "directionSensitive",
                               "Specify direction sensitivity in processing relation pairs Default is 'false'.",
                               TypeConverters.toBoolean)
    filterByTokenDistance = Param(Params._dummy(), "maxSyntacticDistance",
                                  "Filtering criterion based on number of token between entities (Default: 0)",
                                  TypeConverters.toInt)
    scopeWindow = Param(Params._dummy(), "scopeWindow", "The scope window of feature generation for relations",
                        TypeConverters.toListInt)

    def setMaxSyntacticDistance(self, distance:int):
        """Sets maximal syntactic distance, as threshold (Default: 0)

        Parameters
        ----------
        distance : int
            Maximal syntactic distance, as threshold (Default: 0)

        """
        return self._set(maxSyntacticDistance=distance)

    def setFromEntity(self, begin_col:str, end_col:str, label_col:str):
        """Sets from entity

        Parameters
        ----------
        begin_col : str
             Column that has a reference of where the chunk begins
        end_col: str
             Column that has a reference of where the chunk ends
        label_col: str
             Column that has a reference what are the type of chunk
        """
        self._set(fromEntityBeginCol=begin_col)
        self._set(fromEntityEndCol=end_col)
        return self._set(fromEntityLabelCol=label_col)


    def setToEntity(self, begin_col:str, end_col:str, label_col:str):
        """Sets to entity

        Parameters
        ----------
        begin_col : str
             Column that has a reference of where the chunk begins
        end_col: str
             Column that has a reference of where the chunk ends
        label_col: str
             Column that has a reference what are the type of chunk
        """
        self._set(toEntityBeginCol=begin_col)
        self._set(toEntityEndCol=end_col)
        return self._set(toEntityLabelCol=label_col)

    def setCustomLabels(self, labels:dict):
        """Sets custom relation labels

        Parameters
        ----------
        labels : dict[str, str]
            Dictionary which maps old to new labels
        """
        cp_labels = labels.copy()
        from sparknlp_jsl.internal import CustomLabels
        return self._set(customLabels=CustomLabels(cp_labels))

    def setRelationDirectionCol(self, col:str):
        """Sets relation direction column

        Parameters
        ----------
        col : str
             Column contains the relation direction values
        """
        return self._set(relationDirectionCol=col)

    def setPretrainedModelPath(self, value:str):
        """Sets location of pretrained model.

        Parameters
        ----------
        value : str
           Path to an already trained model saved to disk, which is used as a starting point for training the new model.
        """
        return self._set(pretrainedModelPath=value)

    def setОverrideExistingLabels(self, value:bool):
        """Sets whether to override already learned tags. Default is 'true'.

        Parameters
        ----------
        value : bool
            Whether to override already learned labels when using a pretrained model to
            initialize the new model. Default is 'true'
        """
        return self._set(overrideExistingLabels=value)

    def setDirectionSensitive(self, value:bool):
        """Sets whether to sensitive for direction in processing relation pairs.
        If it is `true`, only relations in the form of "ENTITY1-ENTITY2" will be considered,
        If it is `false`, both "ENTITY1-ENTITY2" and "ENTITY2-ENTITY1" relations will be considered,

        Parameters
        ----------
        value : bool
             Whether to sensitive for direction in processing relation pairs.
             Default is 'False'
        """
        return self._set(directionSensitive=value)

    def setFilterByTokenDistance(self, distance:int):

        """Sets number of tokens between entities. (Default: 0)
           Model only finds relations that have fewer than the specified number of tokens between them.

        Parameters
        ----------
        distance : int
            filtering criterion based on number of token between entities. (Default: 0)

        """
        return self._set(filterByTokenDistance=distance)

    def setScopeWindow(self, value):
        """Sets the scope of the window of the feature generation for relations
        Parameters
        ----------
        value : [int, int]
            Left and right offset if the scope window. Offsets must be non-negative values
        """
        assert(type(value) is list)
        assert(len(value) == 2)
        assert(value[0] >= 0)
        assert(value[1] >= 0)

        return self._set(scopeWindow=value)

    def __init__(self, classname="com.johnsnowlabs.nlp.annotators.re.RelationExtractionApproach"):
        super(RelationExtractionApproach, self).__init__(classname=classname)
        self._setDefault(
            pretrainedModelPath="",
            overrideExistingLabels=True,
            maxSyntacticDistance=0,
            directionSensitive=False,
            filterByTokenDistance= 0,
            scopeWindow=[-1,-1]
        )


class RelationExtractionModel(GenericClassifierModel, HandleExceptionParams):
    """Extracts and classifies instances of relations between named entities.

    This is the AnnotatorModel version, if you want to train a model,
    use :class:`RelationExtractionApproach`.

    Visit `NLP Models Hub <https://nlp.johnsnowlabs.com/models>`_ for existing pretrained models.

    ===========================================  ======================
    Input Annotation types                       Output Annotation type
    ===========================================  ======================
    ``WORD_EMBEDDINGS, POS, CHUNK, DEPENDENCY``  ``CATEGORY``
    ===========================================  ======================

    Parameters
    ----------
    predictionThreshold
        Minimal activation of the target unit to encode a new relation instance.
    relationPairs
        List of dash-separated pairs of named entities.
        For example, ["Biomarker-RelativeDay"] will process all relations between entities
        of type "Biomarker" and "RelativeDay".
    relationPairsCaseSensitive
        Determines whether relation pairs are case sensitive.
    relationTypePerPair
        List of entity pairs per relations which limit the entities can form a relation.
        For example, {"CAUSE": ["PROBLEM", "SYMPTOM"]} which only let a "CAUSE" relation to hold
        between a problem ("PROBLEM) and a symptom ("SYMTOM").
    maxSyntacticDistance
        Maximal syntactic distance, as threshold (Default: 0)
    customLabels
        Custom relation labels.
    directionSensitive
        Specify direction sensitivity in processing relation pairs Default is 'false'.
    filterByTokenDistance
        Filtering criterion based on number of token between entities (Default: 0).
    scopeWindow
        The scope window of the feature generation for relations. Default :[-1, -1].

    Examples
    --------

    >>> import sparknlp
    >>> from sparknlp.base import *
    >>> from sparknlp_jsl.common import *
    >>> from sparknlp.annotator import *
    >>> from sparknlp.training import *
    >>> import sparknlp_jsl
    >>> from sparknlp_jsl.base import *
    >>> from sparknlp_jsl.annotator import *
    >>> from pyspark.ml import Pipeline
    >>> documentAssembler = DocumentAssembler() \\
    ...   .setInputCol("text") \\
    ...   .setOutputCol("document")
    ...
    >>> tokenizer = Tokenizer() \\
    ...   .setInputCols(["document"]) \\
    ...   .setOutputCol("tokens")
    ...
    >>> embedder = WordEmbeddingsModel \\
    ...   .pretrained("embeddings_clinical", "en", "clinical/models") \\
    ...   .setInputCols(["document", "tokens"]) \\
    ...   .setOutputCol("embeddings")
    ...
    >>> posTagger = PerceptronModel \\
    ...   .pretrained("pos_clinical", "en", "clinical/models") \\
    ...   .setInputCols(["document", "tokens"]) \\
    ...   .setOutputCol("posTags")
    ...
    >>> nerTagger = MedicalNerModel \\
    ...   .pretrained("ner_events_clinical", "en", "clinical/models") \\
    ...   .setInputCols(["document", "tokens", "embeddings"]) \\
    ...   .setOutputCol("ner_tags")
    ...
    >>> nerConverter = NerConverter() \\
    ...   .setInputCols(["document", "tokens", "ner_tags"]) \\
    ...   .setOutputCol("nerChunks")
    ...
    >>> depencyParser = DependencyParserModel \\
    ...   .pretrained("dependency_conllu", "en") \\
    ...   .setInputCols(["document", "posTags", "tokens"]) \\
    ...   .setOutputCol("dependencies")
    ...
    >>> relationPairs = [
    ...   "direction-external_body_part_or_region",
    ...   "external_body_part_or_region-direction",
    ...   "direction-internal_organ_or_component",
    ...   "internal_organ_or_component-direction"
    ... ]
    ...
    >>> re_model = RelationExtractionModel.pretrained("re_bodypart_directions", "en", "clinical/models") \\
    ...     .setInputCols(["embeddings", "pos_tags", "ner_chunks", "dependencies"]) \\
    ...     .setOutputCol("relations") \\
    ...     .setRelationPairs(relationPairs) \\
    ...     .setMaxSyntacticDistance(4) \\
    ...     .setPredictionThreshold(0.9)
    ...
    >>> pipeline = Pipeline(stages=[
    ...     documentAssembler,
    ...     tokenizer,
    ...     embedder,
    ...     posTagger,
    ...     nerTagger,
    ...     nerConverter,
    ...     depencyParser,
    ...     re_model])

    >>> model = pipeline.fit(trainData)
    >>> data = spark.createDataFrame([["MRI demonstrated infarction in the upper brain stem , left cerebellum and  right basil ganglia"]]).toDF("text")
    >>> result = pipeline.fit(data).transform(data)
    ...
    >>> result.selectExpr("explode(relations) as relations")
    ...  .select(
    ...    "relations.metadata.chunk1",
    ...    "relations.metadata.entity1",
    ...    "relations.metadata.chunk2",
    ...    "relations.metadata.entity2",
    ...    "relations.result"
    ...  )
    ...  .where("result != 0")
    ...  .show(truncate=False)
    ...
    ... # Show results
    ... result.selectExpr("explode(relations) as relations") \\
    ...   .select(
    ...      "relations.metadata.chunk1",
    ...      "relations.metadata.entity1",
    ...      "relations.metadata.chunk2",
    ...      "relations.metadata.entity2",
    ...      "relations.result"
    ...   ).where("result != 0") \\
    ...   .show(truncate=False)
    +------+---------+-------------+---------------------------+------+
    |chunk1|entity1  |chunk2       |entity2                    |result|
    +------+---------+-------------+---------------------------+------+
    |upper |Direction|brain stem   |Internal_organ_or_component|1     |
    |left  |Direction|cerebellum   |Internal_organ_or_component|1     |
    |right |Direction|basil ganglia|Internal_organ_or_component|1     |
    +------+---------+-------------+---------------------------+------+

    """
    inputAnnotatorTypes = [AnnotatorType.WORD_EMBEDDINGS, AnnotatorType.POS, AnnotatorType.CHUNK, AnnotatorType.DEPENDENCY]
    outputAnnotatorType = AnnotatorType.CATEGORY

    name = "RelationExtractionModel"

    predictionThreshold = Param(Params._dummy(), "predictionThreshold",
                                "Minimal activation of the target unit to encode a new relation instance",
                                TypeConverters.toFloat)

    relationPairs = Param(Params._dummy(), "relationPairs",
                          "List of dash-separated pairs of named entities to be processed",
                          TypeConverters.toString)

    relationPairsCaseSensitive = Param(Params._dummy(), "relationPairsCaseSensitive", "Determines whether relation pairs are case sensitive",
                                       TypeConverters.toBoolean)

    maxSyntacticDistance = Param(Params._dummy(), "maxSyntacticDistance",
                                 "Maximal syntactic distance, as threshold (Default: 0)",
                                 TypeConverters.toInt)

    customLabels = Param(Params._dummy(), "customLabels",
                         "Custom relation labels to be used in the relation extraction model",
                         TypeConverters.toListString)

    classes = Param(Params._dummy(), "classes", "Categorization classes", TypeConverters.toListString)

    multiClass = Param(Params._dummy(), "multiClass", "Add the confidence scores or all labels to the metadata",
                       typeConverter=TypeConverters.toBoolean)

    featureScaling = Param(Params._dummy(), "featureScaling",
                           "Feature scaling method. Possible values are 'zscore', 'minmax' or empty (no scaling)",
                           TypeConverters.toString)

    directionSensitive = Param(Params._dummy(), "directionSensitive",
                               "Specify direction sensitivity in processing relation pairs Default is 'false'.",
                               TypeConverters.toBoolean)

    filterByTokenDistance = Param(Params._dummy(), "maxSyntacticDistance",
                                  "Filtering criterion based on number of token between entities (Default: 0)",
                                  TypeConverters.toInt)

    scopeWindow = Param(Params._dummy(), "scopeWindow", "The scope window of feature generation for relations",
                        TypeConverters.toListInt)


    def setMaxSyntacticDistance(self, distance):
        """Sets maximal syntactic distance, as threshold (Default: 0).

        Determine how far the "from entity" can be from the "to entity" in the text.
        Increasing this value will increase recall, but also increase the number of false positives.

        Parameters
        ----------
        distance : int
            Maximal syntactic distance, as threshold (Default: 0)

        """
        return self._set(maxSyntacticDistance=distance)

    def setPredictionThreshold(self, threshold:float):
        """Sets Minimal activation of the target unit to encode a new relation instance.

        Parameters
        ----------
        threshold : float
            Minimal activation of the target unit to encode a new relation instance

        """
        return self._set(predictionThreshold=threshold)

    def setRelationPairs(self, pairs):
        """Sets List of dash-separated pairs of named entities to be processed.

        Parameters
        ----------
        pairs : str or list[str]
            List of dash-separated pairs of named entities to be processed.
        """
        if not isinstance(pairs, list):
            pairs_str = pairs
        else:
            pairs_str = ",".join(pairs)
        return self._set(relationPairs=pairs_str)

    def setRelationPairsCaseSensitive(self, value:bool):
        """Sets the case sensitivity of relation pairs
        
        Parameters
        ----------
        value : bool
            whether relation pairs are case sensitive
        """
        return self._set(relationPairsCaseSensitive=value)

    def setCustomLabels(self, labels:dict):
        """Sets custom relation labels

        Parameters
        ----------
        labels : dict[str, str]
            Dictionary which maps old to new labels
        """
        self._call_java("setCustomLabels",labels)
        return self

    def getClasses(self):
        """Returns labels used to train this model.
        """
        return self._call_java("getClasses")

    def setMultiClass(self, value:bool):
        """Sets the model in multi class prediction mode (Default: false).

        Parameters
        ----------
        value : bool
           Whether to return only the label with the highest confidence score or all labels
        """
        return self._set(multiClass=value)

    def setFeatureScaling(self, feature_scaling:str):
        """Sets Feature scaling method. 
        
        Possible values are 'zscore', 'minmax' or empty (no scaling).

        Parameters
        ----------
        feature_scaling : str
            Feature scaling method. Possible values are 'zscore', 'minmax' or empty (no scaling).

        """
        return self._set(featureScaling=feature_scaling)

    def setDirectionSensitive(self, value:bool):
        """Sets whether to sensitive for direction in processing relation pairs.
        If it is `true`, only relations in the form of "ENTITY1-ENTITY2" will be considered,
        If it is `false`, both "ENTITY1-ENTITY2" and "ENTITY2-ENTITY1" relations will be considered,

        Parameters
        ----------
        value : bool
             Whether to sensitive for direction in processing relation pairs.
             Default is 'False'
        """
        return self._set(directionSensitive=value)

    def setFilterByTokenDistance(self, distance:int):

        """Sets number of tokens between entities. (Default: 0)
           Model only finds relations that have fewer than the specified number of tokens between them.

        Parameters
        ----------
        distance : int
            filtering criterion based on number of token between entities. (Default: 0)

        """
        self._call_java("setFilterByTokenDistance", distance)
        return self

    def setScopeWindow(self, value):
        """Sets the scope of the window of the feature generation for relations
        Parameters
        ----------
        value : [int, int]
            Left and right offset if the scope window. Offsets must be non-negative values
        """
        assert(type(value) is list)
        assert(len(value) == 2)
        assert(value[0] >= 0)
        assert(value[1] >= 0)

        return self._set(scopeWindow=value)

    def __init__(self, classname="com.johnsnowlabs.nlp.annotators.re.RelationExtractionModel",
                 java_model=None):
        super(RelationExtractionModel, self).__init__(
            classname=classname,
            java_model=java_model
        )
        self._setDefault(
            relationPairsCaseSensitive=False,
            maxSyntacticDistance=0,
            predictionThreshold=0.5,
            relationPairs="",
            multiClass=False,
            featureScaling="",
            directionSensitive=False,
            filterByTokenDistance= 0,
            scopeWindow=[-1,-1]
        )

    def setRelationTypePerPair(self, relationTypePairs):
        """Set the list of entity pairs allowed for a given relation.

        Parameters
        ----------
        relationTypePairs : dict[str, list[str]]
            Dictionary which maps relation types to a list of entity pairs.

        """

        self._call_java("setRelationTypePerPair", relationTypePairs)
        return self

    def getRelationTypePerPair(self):
        """Return the list of entity pairs allowed for a given relation.
        """

        rel_pairs = self._call_java("getRelationTypePerPairStr")
        rel_pairs_dict = {}
        for t in rel_pairs.split("\n"):
            parts = t.split(":")
            if len(parts) == 2:
                rel, pairs = parts
                pairs = pairs.split(",")
                rel_pairs_dict[rel] = pairs

        return rel_pairs_dict

    @staticmethod
    def pretrained(name="posology_re", lang="en", remote_loc="clinical/models"):
        """Download a pre-trained RelationExtractionModel.

        Parameters
        ----------
        name : str
            Name of the pre-trained model, by default "posology_re"
        lang : str
            Language of the pre-trained model, by default "en"
        remote_loc : str
            Remote location of the pre-trained model. If None, use the
            open-source location. Other values are "clinical/models",
            "finance/models", or "legal/models".

        Returns
        -------
        RelationExtractionModel
            A pre-trained RelationExtractionModel.
        """
        from sparknlp_jsl.pretrained import InternalResourceDownloader
        if name == "posology_re":
            return PosologyREModel()
        elif name == "generic_re":
            return GenericREModel()
        else:
            return InternalResourceDownloader.downloadModel(RelationExtractionModel, name, lang, remote_loc,
                                                    j_dwn='InternalsPythonResourceDownloader')

class PosologyREModel(RelationExtractionModel):
    """
    Model for Posology Relation Extraction.

    Instantiated RelationExtractionModel for extracting relationships between different recognized drug entitites.
    This class is not intended to be directly used, please use the RelationExtractionModel instead.
    Possible values are "DRUG-DOSAGE", "DRUG-ADE", "DRUG-FORM", "DRUG-FREQUENCY",
    "DRUG-ROUTE", "DRUG-REASON", "DRUG-STRENGTH", "DRUG-DURATION".
     """
    def __init__(self, classname="com.johnsnowlabs.nlp.annotators.re.PosologyREModel",
                 java_model=None):
        super(RelationExtractionModel, self).__init__(
            classname=classname,
            java_model=java_model
        )

class GenericREModel(RelationExtractionModel):
    """
    Generic Relation Extraction Model.

    Instantiated RelationExtractionModel for extracting relationships between any entities.
    This class is not intended to be directly used, please use the RelationExtractionModel instead.
    Pairs of entities should be specified using setRelationPairs.
    """
    def __init__(self, classname="com.johnsnowlabs.nlp.annotators.re.GenericREModel",
                 java_model=None):
        super(RelationExtractionModel, self).__init__(
            classname=classname,
            java_model=java_model
        )