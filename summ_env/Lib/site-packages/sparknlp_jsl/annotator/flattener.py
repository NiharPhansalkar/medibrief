from sparknlp_jsl.annotator import *


class Flattener(AnnotatorTransformer):
    """Converts annotation results into a format that easier to use.

    The Flattener produces a DataFrame with flattened and exploded columns containing
    annotation results, making it easier to interpret and analyze the information.
    It is particularly useful for extracting and organizing the results obtained from Spark NLP Pipelines.


    ====================== ======================
    Input Annotation types Output Annotation type
    ====================== ======================
    ``ANY``                ``NONE``
    ====================== ======================

    Parameters
    ----------
    inputCols
        Input annotations
    cleanAnnotations
        Whether to remove annotation columns, by default True
    explodeSelectedFields
        Dict of input columns to their corresponding selected fields
    flattenExplodedColumns
        Whether to flatten exploded columns(default : true)
    orderByColumn
        Specify the column by which the DataFrame should be ordered.
    orderDescending
        specifying whether to order the DataFrame in descending order.(default : true)


    Examples
    --------
    >>> import sparknlp
    >>> from sparknlp.base import *
    >>> from sparknlp.annotator import *
    >>> from sparknlp.pretrained import PretrainedPipeline
    >>> data = spark.createDataFrame([["He is an elderly gentleman in no acute distress."]]).toDF("text")

    >>> documentAssembler = DocumentAssembler().setInputCol("text").setOutputCol("document")
    >>> sentenceDetector = SentenceDetector().setInputCols(["document"]).setOutputCol("sentence")
    >>> tokenizer = Tokenizer().setInputCols(["sentence"]).setOutputCol("token")
    >>> word_embeddings = WordEmbeddingsModel.pretrained("embeddings_clinical", "en", "clinical/models")
    >>>    .setInputCols(["sentence", "token"]).setOutputCol("embeddings")
    >>> clinical_ner = MedicalNerModel.pretrained("ner_jsl", "en", "clinical/models")
    >>>    .setInputCols(["sentence", "token", "embeddings"]).setOutputCol("ner")
    >>> ner_converter = NerConverterInternal().setInputCols(["sentence", "token", "ner"]).setOutputCol("ner_chunk") \
    >>> clinical_assertion = AssertionDLModel.pretrained("assertion_jsl_augmented", "en", "clinical/models")
    >>>    .setInputCols(["sentence", "ner_chunk", "embeddings"]).setOutputCol("assertion") \
    >>>    .setEntityAssertionCaseSensitive(False)

    >>> nlpPipeline = Pipeline(stages=[documentAssembler, sentenceDetector,tokenizer, word_embeddings,clinical_ner, ner_converter,clinical_assertion, finisher) ])
    >>> flattener = Flattener()
    >>>        .setInputCols("sentence", "ner_chunk", "assertion") \
    >>>        .setExplodeSelectedFields({"ner_chunk": ["result", "metadata.entity"],
    >>>                                   "assertion": ["result", "metadata.confidence"]}) \
    >>>        .setOrderByColumn("assertion_metadata_confidence")
    >>> explainResult = pipeline.transform(data)

    >>> model = nlpPipeline.fit(data).transform(data)
    >>> model.select("finished_ner_chunk_exploded").show(truncate=False)

    Show results.
        +----------------+-------------------------+----------------+-----------------------------+
        |ner_chunk_result|ner_chunk_metadata_entity|assertion_result|assertion_metadata_confidence|
        +----------------+-------------------------+----------------+-----------------------------+
        |elderly         |Age                      |Present         |0.9885                       |
        |gentleman       |Gender                   |Absent          |0.9976                       |
        |He              |Gender                   |SomeoneElse     |0.9994                       |
        |acute           |Modifier                 |Absent          |1.0                          |
        |distress        |Symptom                  |Absent          |1.0                          |
        +----------------+-------------------------+----------------+-----------------------------+


    """
    name = "Flattener"
    inputCols = Param(Params._dummy(), "inputCols", "input annotations", typeConverter=TypeConverters.toListString)

    cleanAnnotations = Param(Params._dummy(), "cleanAnnotations", "whether to remove annotation columns",
                             typeConverter=TypeConverters.toBoolean)
    flattenExplodedColumns = Param(Params._dummy(), "flattenExplodedColumns", "Whether to flatten exploded columns(default : true)",
                             typeConverter=TypeConverters.toBoolean)
    orderByColumn = Param(Params._dummy(), "orderByColumn", "specify the column by which the DataFrame should be ordered.",
                          typeConverter=TypeConverters.toString)
    orderDescending = Param(Params._dummy(), "orderDescending", "specifying whether to order the DataFrame in descending order.(default : true)",
                              typeConverter=TypeConverters.toBoolean)
    keepOriginalColumns = Param(Params._dummy(), "keepOriginalColumns", "array of column names that should be kept in the DataFrame after the flattening process.",
                             typeConverter=TypeConverters.toListString)


    def setInputCols(self, *value):
        """Sets column names of input annotations.
           If `explodeSelectedFields` is not set (default), the transformation will return all
           information for the specified columns.

        Parameters
        ----------
        *value : str
            Input columns for the annotator
        """
        if len(value) == 1 and type(value[0]) == list:
            return self._set(inputCols=value[0])
        else:
            return self._set(inputCols=list(value))


    def setCleanAnnotations(self, value):
        """Sets whether to remove annotation columns, by default True.

        Parameters
        ----------
        value : bool
            Whether to remove annotation columns
        """
        return self._set(cleanAnnotations=value)



    def getInputCols(self):
        """Gets input columns name of annotations."""
        return self.getOrDefault(self.inputCols)


    def setExplodeSelectedFields(self, value):
        """
        Sets a dict of input columns to their corresponding selected fields.

        When set, the transformation returns an exploded column for each specified field containing annotation data.
        This allows you to choose and explode only the desired fields.

        If `explodeSelectedFields` is not set (default), the transformation will return all
        information for the specified columns.

        Alias can be given with as

        Parameters
        ----------
        value : dict
            Map of input columns to their corresponding selected fields
        """
        self._call_java("setExplodeSelectedFields", value)
        return self

    def setFlattenExplodedColumns(self, value):
        """Sets whether to flatten exploded columns.
        When `true`(the default), the transformation returns a flattened and exploded columns containing annotation data,
        providing a comprehensive view of the annotated information.

        When set to `false` , the transformation returns exploded columns
        without flattening

        Parameters
        ----------
        value : bool
            whether to flatten exploded columns
        """
        return self._set(flattenExplodedColumns=value)

    def setOrderByColumn(self, value):
        """Sets the column by which the DataFrame should be ordered.
           flattenExplodedColumns must be true for ordering

        Parameters
        ----------
        value : bool
            the column by which the DataFrame should be ordered.
        """
        return self._set(orderByColumn=value)

    def setOrderDescending(self, value):
        """Sets whether to order the DataFrame in descending order.(default : true)
           flattenExplodedColumns must be true for ordering

        Parameters
        ----------
        value : bool
            whether to order the DataFrame in descending order.(default : true)
        """
        return self._set(orderDescending=value)

    def setKeepOriginalColumns(self, value):
        """Sets array of column names that should be kept in the DataFrame
           after the flattening process. These columns will not be affected
           by the flattening operation and will be included in the final
           output as they are.

        Parameters
        ----------
        value : list[str]
            Array of column names that should be kept in the DataFrame
            after the flattening process.
        """
        return self._set(keepOriginalColumns=value)

    @keyword_only
    def __init__(self):
        super(Flattener, self).__init__(classname="com.johnsnowlabs.nlp.annotators.Flattener")
        self._setDefault(
            cleanAnnotations=True,
            flattenExplodedColumns=True,
        )

    @keyword_only
    def setParams(self):
        kwargs = self._input_kwargs
        return self._set(**kwargs)

