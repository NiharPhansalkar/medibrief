#  Copyright 2017-2022 John Snow Labs
#
#  Licensed under the Apache License, Version 2.0 (the "License");
#  you may not use this file except in compliance with the License.
#  You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
#  Unless required by applicable law or agreed to in writing, software
#  distributed under the License is distributed on an "AS IS" BASIS,
#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
#  See the License for the specific language governing permissions and
#  limitations under the License.
"""Contains classes for Resolution2Chunk."""

from pyspark import keyword_only
from sparknlp.internal import AnnotatorTransformer
from sparknlp_jsl.common import AnnotatorProperties, AnnotatorType
from sparknlp_jsl.utils.licensed_annotator_type import InternalAnnotatorType


class Resolution2Chunk(AnnotatorTransformer, AnnotatorProperties):
    """Converts ``Resolution`` type annotations into ``CHUNK`` type with the
    contents of a ``chunkCol``.

    Chunk text must be contained within input ``DOCUMENT``. May be either
    ``StringType`` or ``ArrayType[StringType]`` (using setIsArray). Useful for
    annotators that require a CHUNK type input.


    ====================== ======================
    Input Annotation types Output Annotation type
    ====================== ======================
    ``Resolution``           ``CHUNK``
    ====================== ======================

    Parameters
    ----------

    Examples
    --------
    >>> import sparknlp
    >>> from sparknlp.base import *
    >>> from sparknlp_jsl.common import *
    >>> from sparknlp.annotator import *
    >>> from sparknlp.training import *
    >>> from pyspark.ml import Pipeline

    >>> documentAssembler = DocumentAssembler().setInputCol("text").setOutputCol("ner_chunk")

    >>> sbert_embedder = BertSentenceEmbeddings.pretrained('sbiobert_base_cased_mli', 'en','clinical/models')\
    >>>  .setInputCols(["ner_chunk"])\
    >>>  .setOutputCol("sentence_embeddings")\
    >>>  .setCaseSensitive(False)

    >>> rxnorm_resolver = SentenceEntityResolverModel.pretrained("sbiobertresolve_rxnorm_augmented","en", "clinical/models")\
    >>>  .setInputCols(["sentence_embeddings"])\
    >>>  .setOutputCol("rxnorm_code")\

    >>> data = spark.createDataFrame(
    >>>    [["I'm ready!"], ["If I could put into words how much I love waking up at 6 am on Mondays I would."]]).toDF(
    >>>    "text")
    >>> resolver2chunk = Resolution2Chunk().setInputCols("resolution").setOutputCol("chunk")

    >>> pipeline = Pipeline().setStages([documentAssembler, sbert_embedder, rxnorm_resolver, resolver2chunk]).fit(data)
    >>> result = pipeline.transform(data)
    >>> result.selectExpr("chunk.result", "chunk.annotatorType").show(truncate=False)
            +--------+-------------+
            |result  |annotatorType|
            +--------+-------------+
            |[219400]|[chunk]      |
            |[13369] |[chunk]      |
            +--------+-------------+


    """
    inputAnnotatorTypes = [InternalAnnotatorType.ASSERTION]
    outputAnnotatorType = AnnotatorType.CHUNK

    name = "Resolution2Chunk"

    @keyword_only
    def __init__(self):
        super(Resolution2Chunk, self).__init__(classname="com.johnsnowlabs.nlp.annotators.resolution.Resolution2Chunk")

    @keyword_only
    def setParams(self):
        kwargs = self._input_kwargs
        return self._set(**kwargs)
