
import pickle
with open('sparknlp_jsl/transpiler/externalSources/OpenSourceAnnotators.pickle', 'rb') as handle:
     open_source_annotator_set_final = pickle.load(handle)

import pickle
with open('sparknlp_jsl/transpiler/externalSources/MedicalAnnotators.pickle', 'rb') as handle:
     medical_annotators_set = pickle.load(handle)


# Guard Functions
def is_component_medical(c):
    return any(item in c.model.name for item in medical_annotators_set)

def is_component_open_source(c):
    return any(item in c.model.name for item in open_source_annotator_set_final)

def is_component_pretrained(c):
    return hasattr(c.model, 'pretrained')

def is_component_finance(c):
    pass

def is_component_legal(c):
    pass

def is_component_ocr(c):
    pass

def starts_with_finance(c):
    pass

def starts_with_legal(c):
    pass

def starts_with_medical(c):
    if c.model.name.lower().startswith("medical"):
        return True
    else:
        return False

def bucket(c):
    if is_component_medical(c):
        bucket_name = "clinical/models"
    elif is_component_finance(c):
        bucket_name = "finance/models"
    elif is_component_legal(c):
        bucket_name = "legal/models"
    elif is_component_ocr(c):
        bucket_name = "ocr/models"
    else:
        bucket_name = False
    return bucket_name


def convert_nlu_component_to_python(c, module):
    if not is_component_pretrained(c):
        name = c.model.name
        if starts_with_medical(c):
            name = name[7:]
        elif starts_with_finance(c):
            pass
        elif starts_with_legal(c):
            pass

        s = f'{c.name} = {module}.{name}'
        if not hasattr(c.model, 'setInputCols'):
            s = f'{s}().setInputCol("{c.spark_input_column_names[0]}")'
        else:
            s = f'{s}().setInputCols({c.spark_input_column_names})'

        if not hasattr(c.model, 'setOutputCols'):
            s = f'{s}.setOutputCol("{c.spark_output_column_names[0]}")\n'
        else:
            s = f'{s}.setOutputCols({c.spark_output_column_names})\n'

    else:
        name = c.model.name
        if starts_with_medical(c):
            name = name[7:]
        elif starts_with_finance(c):
            pass
        elif starts_with_legal(c):
            pass

        s = f'{c.name} = {module}.{name}'
        if not bucket(c):
            s = f'{s}.pretrained("{c.nlp_ref}", "{c.language}")'
        else:
            s = f'{s}.pretrained("{c.nlp_ref}", "{c.language}", "{bucket(c)}")'

        if not hasattr(c.model, 'setInputCols'):
            s = f'{s}.setInputCol("{c.spark_input_column_names[0]}")'
        else:
            s = f'{s}.setInputCols({c.spark_input_column_names})'

        if not hasattr(c.model, 'setOutputCols') == 1:
            s = f'{s}.setOutputCol("{c.spark_output_column_names[0]}")\n'
        else:
            s = f'{s}.setOutputCols({c.spark_output_column_names})\n'

    return s


# NLU Component to Spark_NLP_Code
def nlu_component_to_spark_nlp_code(c):
    if is_component_medical(c):
        return convert_nlu_component_to_python(c, "medical")
    elif is_component_open_source(c):
        return convert_nlu_component_to_python(c, "nlp")
    elif is_component_ocr(c):
        return convert_nlu_component_to_python(c, "ocr")
    elif is_component_finance(c):
        return convert_nlu_component_to_python(c, "finance")
    elif is_component_legal(c):
        return convert_nlu_component_to_python(c, "legal")
    else:
        raise Exception("Uncovered Case")


# NLU Pipeline to Python Code
def to_python(pipeline_to_convert):
    result = ''
    list_of_stages = []
    for c in pipeline_to_convert.components:
        result += nlu_component_to_spark_nlp_code(c)
        list_of_stages.append(c.name)

    final_result = result + f"pipeline = Pipeline(stages={'[%s]' % ', '.join(map(str, list_of_stages))})"
    print(final_result)
    return (final_result)