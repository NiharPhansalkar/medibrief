import unittest
from pyspark.ml import Pipeline
from pyspark.ml import PipelineModel
from pyspark.sql import DataFrame
from sparknlp.pretrained import PretrainedPipeline

import sparknlp_jsl
from sparknlp_jsl.annotator import *

from sparknlp_jsl.pipeline_tracer import PipelineTracer
from test_jsl.util import SparkContextForTest


class PipelineTracerTestCase(unittest.TestCase):
    spark = SparkContextForTest.spark

    def printTracer(self, model_name, language="en", source="clinical/models"):
        pretrained_pipeline = PretrainedPipeline(model_name, language, source)
        tracer = PipelineTracer(pretrained_pipeline)
        print(tracer.createParserDictionary())
        print(f"Entities: {tracer.getPossibleEntities()}")
        print(f"Assertions: {tracer.getPossibleAssertions()}")
        print(f"Relations: {tracer.getPossibleRelations()}")
        tracer.printPipelineSchema()

    def test_clinical_deidentification(self):
        self.printTracer("clinical_deidentification")

    def test_explain_clinical_doc_generic(self):
        self.printTracer("explain_clinical_doc_generic")


    def test_get_pipeline_stages(self):
        pretrained_pipeline = PretrainedPipeline('explain_clinical_doc_generic', 'en', "clinical/models")
        tracer = PipelineTracer(pretrained_pipeline)
        #print(type(tracer.getPipelineStages()))
        #print(tracer.getPipelineStages())
        stages = tracer.getPipelineStages()
        for stage in stages:
            print(stage.__dict__())
        print("****************")
        for stage in stages:
            print(stage.__dict__dict__())

    def test_pipeline_model(self):

        document_assembler = DocumentAssembler() \
            .setInputCol("text") \
            .setOutputCol("document")

        sentence_detector = SentenceDetector() \
            .setInputCols(["document"]) \
            .setOutputCol("sentence")

        tokenizer = Tokenizer() \
            .setInputCols(["sentence"]) \
            .setOutputCol("token")

        word_embeddings = WordEmbeddingsModel \
            .pretrained("embeddings_clinical", "en", "clinical/models") \
            .setInputCols(["sentence", "token"]) \
            .setOutputCol("embeddings")

        clinical_ner = MedicalNerModel \
            .pretrained("ner_clinical", "en", "clinical/models") \
            .setInputCols(["sentence", "token", "embeddings"]) \
            .setOutputCol("ner")

        ner_converter = NerConverterInternal() \
            .setInputCols(["sentence", "token", "ner"]) \
            .setOutputCol("ner_chunk") \
            .setWhiteList(["TREATMENT", "PROBLEM"])

        clinical_assertion = AssertionDLModel \
            .pretrained("assertion_dl_large", "en", "clinical/models") \
            .setInputCols(["sentence", "ner_chunk", "embeddings"]) \
            .setOutputCol("assertion") \
            .setIncludeConfidence(True) \
            .setEntityAssertionCaseSensitive(False) \
            .setEntityAssertion({"treAtment": ["present"]}) \
            .setReplaceLabels({"PRESENT": "available", "absent": "none", "Conditional": "Optional"})

        pipeline = Pipeline(stages=[
            document_assembler,
            sentence_detector,
            tokenizer,
            word_embeddings,
            clinical_ner,
            ner_converter,
            clinical_assertion])

        model = pipeline.fit(self.spark.createDataFrame([[""]]).toDF("text"))
        tracer = PipelineTracer(model)
        assert tracer.getPossibleAssertions() == ['available', 'none', 'hypothetical', 'possible', 'Optional', 'associated_with_someone_else']
        assert tracer.getPossibleEntities() == ['TREATMENT', 'PROBLEM']
        assert tracer.getPossibleRelations() == []


    def test_pipeline_parser_dict_directly(self):
        columns = PipelineTracer.getParserDictDirectly("clinical_deidentification", "en", "clinical/models")
        assert type(columns) == dict
        assert columns != {} and columns is not None
        assert columns == {'document_identifier': 'clinical_deidentification', 'document_text': 'sentence', 'entities': ['ner_chunk'], 'assertions': [], 'resolutions': [], 'relations': [], 'summaries': [], 'deidentifications': [{'original': 'sentence', 'obfuscated': 'obfuscated', 'masked': ''}], 'classifications': []}


    def test_list_available_models(self):
        models = PipelineTracer.listAvailableModels("en", "clinical/models")
        assert type(models) == list
        assert models != [] and models is not None
        assert "clinical_deidentification" in models

    def test_show_available_models(self):
        PipelineTracer.showAvailableModels("en", "clinical/models")

    def test_parser_dict_compatibility(self):
        pretrained_pipeline = PretrainedPipeline("explain_clinical_doc_vop", "en", "clinical/models")
        tracer = PipelineTracer(pretrained_pipeline)
        parser_dict = tracer.createParserDictionary()
        parser_dict.update({'document_identifier': 'explain_clinical_doc_vop'})
        parser = PipelineTracer.getParserDictDirectly("explain_clinical_doc_vop", "en", "clinical/models")
        assert type(parser_dict) == dict
        assert type(parser) == dict
        assert parser_dict == parser

    def test_get_parser_dict_directly(self):
        models = PipelineTracer.listAvailableModels("en", "clinical/models")
        for model in models:
            parser = PipelineTracer.getParserDictDirectly(model, "en", "clinical/models")
            assert type(parser) == dict
            assert parser != {} and parser is not None
            print(parser)

if __name__ == '__main__':
    unittest.main()


