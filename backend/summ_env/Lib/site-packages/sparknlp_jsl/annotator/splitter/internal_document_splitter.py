from sparknlp.annotator import DocumentCharacterTextSplitter
from sparknlp_jsl.common import *


class InternalDocumentSplitter(AnnotatorModelInternal, DocumentCharacterTextSplitter):
    """Annotator which splits large documents into small documents.

    InternalDocumentSplitter has setSplitMode method to decide how to split documents.
    If splitMode is 'recursive', It takes the separators in order and
    splits subtexts if they are over the chunk length, considering optional overlap of the chunks.

    For example, given chunk size 20 and overlap 5:

    .. code-block:: python

        "He was, I take it, the most perfect reasoning and observing machine that the world has seen."

        ["He was, I take it,", "it, the most", "most perfect", "reasoning and", "and observing", "machine that the", "the world has seen."]


    Additionally, you can set

    - custom patterns with setSplitPatterns
    - whether patterns should be interpreted as regex with setPatternsAreRegex
    - whether to keep the separators with setKeepSeparators
    - whether to trim whitespaces with setTrimWhitespace
    - whether to explode the splits to individual rows with setExplodeSplits

    ====================== ======================  =================================
    Input Annotation types Output Annotation type  Optional Input Annotation types
    ====================== ======================  =================================
    ``DOCUMENT``           ``DOCUMENT``            ``DOCUMENT(Sentence)``, ``TOKEN``
    ====================== ======================  =================================

    Parameters
    ----------

    chunkSize
        Size of each chunk of text. This param is applicable only for "recursive" splitMode.
    chunkOverlap
        Length of the overlap between text chunks, by default `0`. This param is applicable only for "recursive" splitMode.
    splitPatterns
        Patterns to split the document. Default for recursive mode ["\n\n", "\n", " ", ""], for regex mode ["(?x)  (?: [ \\t\\r\\f\\v]*? \\n ){2}  [ \\t\\r\\f\\v]*?"]
    patternsAreRegex
        Whether to interpret the split patterns as regular expressions, by default `True`.
    keepSeparators
        Whether to keep the separators in the final result , by default `True`. This param is applicable only for "recursive" splitMode.
    explodeSplits
        Whether to explode split chunks to separate rows , by default `False`.
    trimWhitespace
        Whether to trim whitespaces of extracted chunks , by default `True`.
    splitMode
        The split mode to determine how text should be segmented. Default: 'regex'. It should be one of the following values:
          - "char": Split text based on individual characters.
          - "token": Split text based on tokens. You should supply tokens from inputCols.
          - "sentence": Split text based on sentences. You should supply sentences from inputCols.
          - "recursive": Split text recursively using a specific algorithm.
          - "regex": Split text based on a regular expression pattern.
    sentenceAwareness
        whether to split the document by sentence awareness if possible.
        If true, it can stop the split process before maxLength.
        If true, you should supply sentences from inputCols. Default: False.
        This param is not applicable only for "regex" and "recursive" splitMode.
    maxLength
        The maximum length allowed for spitting. The mode in which the maximum length is specified:
        - "char": Maximum length is measured in characters. Default: 512
        - "token": Maximum length is measured in tokens. Default: 128
        - "sentence": Maximum length is measured in sentences. Default: 8
    customBoundsStrategy
        The custom bounds strategy for text splitting using regular expressions. This param is applicable only for "regex" splitMode.
    caseSensitive
        Whether to use case sensitive when matching regex, by default `False`. This param is applicable only for "regex" splitMode.
   metaDataFields
        Metadata fields to add specified data in columns to the metadata of the split documents.
        You should set column names to read columns.
    enableSentenceIncrement
        Whether the sentence index should be incremented in the metadata of the annotator.
        When set to true, the annotator will increment the sentence index in the metadata for each split documents. Default: False.

    Examples
    --------
    >>> import sparknlp
    >>> from sparknlp.base import *
    >>> from sparknlp.annotator import *
    >>> from pyspark.ml import Pipeline
    >>> textDF = spark.read.text(
    ...    "/home/john/resources/spell/sherlockholmes.txt",
    ...    wholetext=True
    ... ).toDF("text")
    >>> documentAssembler = DocumentAssembler().setInputCol("text")
    >>> textSplitter = InternalDocumentSplitter() \\
    ...     .setInputCols(["document"]) \\
    ...     .setOutputCol("splits") \\
    ...     .setSplitMode("recursive") \\
    ...     .setChunkSize(20000) \\
    ...     .setChunkOverlap(200) \\
    ...     .setExplodeSplits(True)
    >>> pipeline = Pipeline().setStages([documentAssembler, textSplitter])
    >>> result = pipeline.fit(textDF).transform(textDF)
    >>> result.selectExpr(
    ...       "splits.result",
    ...       "splits[0].begin",
    ...       "splits[0].end",
    ...       "splits[0].end - splits[0].begin as length") \\
    ...     .show(8, truncate = 80)
    +--------------------------------------------------------------------------------+---------------+-------------+------+
    |                                                                          result|splits[0].begin|splits[0].end|length|
    +--------------------------------------------------------------------------------+---------------+-------------+------+
    |[ Project Gutenberg's The Adventures of Sherlock Holmes, by Arthur Conan Doyl...|              0|        19994| 19994|
    |["And Mademoiselle's address?" he asked.\n\n"Is Briony Lodge, Serpentine Aven...|          19798|        39395| 19597|
    |["How did that help you?"\n\n"It was all-important. When a woman thinks that ...|          39371|        59242| 19871|
    |["'But,' said I, 'there would be millions of red-headed men who\nwould apply....|          59166|        77833| 18667|
    |[My friend was an enthusiastic musician, being himself not only a\nvery capab...|          77835|        97769| 19934|
    |["And yet I am not convinced of it," I answered. "The cases which\ncome to li...|          97771|       117248| 19477|
    |["Well, she had a slate-coloured, broad-brimmed straw hat, with a\nfeather of...|         117250|       137242| 19992|
    |["That sounds a little paradoxical."\n\n"But it is profoundly True. Singulari...|         137244|       157171| 19927|
    +--------------------------------------------------------------------------------+---------------+-------------+------+

    """
    name = "InternalDocumentSplitter"

    inputAnnotatorTypes = [AnnotatorType.DOCUMENT]
    optionalInputAnnotatorTypes = [AnnotatorType.DOCUMENT, AnnotatorType.TOKEN]
    outputAnnotatorType = AnnotatorType.DOCUMENT

    splitMode = Param(Params._dummy(),
                      "splitMode",
                      "The split mode to determine how text should be segmented",
                      typeConverter=TypeConverters.toString)
    sentenceAwareness = Param(Params._dummy(),
                              "sentenceAwareness",
                              "Whether to split document by sentence awareness if possible",
                              typeConverter=TypeConverters.toBoolean)
    maxLength = Param(Params._dummy(),
                         "maxLength",
                         "The maximum length for text parsing based on the specified mode",
                         typeConverter=TypeConverters.toInt)
    customBoundsStrategy = Param(Params._dummy(),
                          "customBoundsStrategy",
                          "How to return matched custom bounds",
                          typeConverter=TypeConverters.toString)
    caseSensitive = Param(Params._dummy(),
                           "caseSensitive",
                           "Whether to use case sensitive when matching regex",
                           typeConverter=TypeConverters.toBoolean)
    metaDataFields = Param(Params._dummy(),
                          "metaDataFields",
                          "Metadata fields to add specified info in columns to the metadata of the split documents",
                          typeConverter=TypeConverters.toListString)
    enableSentenceIncrement = Param(Params._dummy(),
                                    "enableSentenceIncrement",
                                    "Whether the sentence index should be incremented in the metadata of the annotator.",
                                    typeConverter=TypeConverters.toBoolean)

    def __init__(self, classname="com.johnsnowlabs.nlp.annotators.splitter.InternalDocumentSplitter", java_model=None):
        super(InternalDocumentSplitter, self).__init__(classname=classname, java_model=java_model)

    def setSplitMode(self, value: str):
        """Sets the split mode to determine how text should be segmented. Default: 'regex'.

        :param value: The split mode to be set. It should be one of the following values:
                  - "char": Split text based on individual characters.
                  - "token": Split text based on tokens. You should supply tokens from inputCols.
                  - "sentence": Split text based on sentences. You should supply sentences from inputCols.
                  - "recursive": Split text recursively using a specific algorithm.
                  - "regex": Split text based on a regular expression pattern.
        Parameters
        ----------
        value : str
            The split mode to determine how text should be segmented. Default: 'regex'.
        """
        return self._set(splitMode=value)

    def setSentenceAwareness(self, value: bool):
        """Sets whether to split the document by sentence awareness if possible.
        If true, it can stop the split process before maxLength.
        If true, you should supply sentences from inputCols. Default: False.

        Parameters
        ----------
        value : bool
            Whether to enable sentence awareness
        """
        return self._set(sentenceAwareness=value)

    def setMaxLength(self, value: int):
        """Sets the maximum length allowed for spitting.

            The mode in which the maximum length is specified:
        - "char": Maximum length is measured in characters. Default: 512
        - "token": Maximum length is measured in tokens. Default: 128
        - "sentence": Maximum length is measured in sentences. Default: 8
        """
        if value < 1:
            raise ValueError("maxLength should be larger than 0.")
        return self._set(maxLength=value)

    def setCustomBoundsStrategy(self, value: str):
        """ Sets the custom bounds strategy for text splitting using regular expressions.

        :param value: The custom bounds strategy to be set. It should be one of the following values:
                  - "none": No custom bounds are applied.
                  - "prepend": Custom bounds are prepended to the split documents.
                  - "append": Custom bounds are appended to the split documents.
        Parameters
        ----------
        value : str
            The custom bounds strategy for text splitting using regular expressions, by default "none".
        """
        return self._set(customBoundsStrategy=value)

    def setCaseSensitive(self, value: bool):
        """Sets whether to use case sensitive when matching regex.

        Parameters
        ----------
        value : bool
            Whether to use case sensitive when matching regex, by default `False`.
        """
        return self._set(caseSensitive=value)

    def setMetaDataFields(self, value):
        """Sets metadata fields to add specified data in columns to the metadata of the split documents.
        You should set column names to read columns.

        Parameters
        ----------
        value: List[str], list of column names
            Metadata fields to add specified data in columns to the metadata of the split documents.
        """
        return self._set(metaDataFields=value)

    def setEnableSentenceIncrement(self, value: bool):
        """Sets whether the sentence index should be incremented in the metadata of the annotator.
        When set to true, the annotator will increment the sentence index in the metadata for each split documents.
        Default: False.

        Parameters
        ----------
        value : bool
            Whether the sentence index should be incremented in the metadata of the annotator. Default: False.
        """
        return self._set(enableSentenceIncrement=value)

    def setInputCols(self, *value):
        """Sets column names of input annotations.

        Parameters
        ----------
        *value : str
            Input columns for the annotator
        """
        if type(value[0]) == str or type(value[0]) == list:
            # self.inputColsValidation(value)
            if len(value) == 1 and type(value[0]) == list:
                return self._set(inputCols=value[0])
            else:
                return self._set(inputCols=list(value))
        else:
            raise TypeError("InputCols datatype not supported. It must be either str or list")

