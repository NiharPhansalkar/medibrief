from sparknlp_jsl.annotator import WhiteBlackListParams
from sparknlp_jsl.common import *


class DocumentFiltererByClassifier(AnnotatorModelInternal, WhiteBlackListParams):
    """ Filters documents by the result of classifier annotators.
    Documents are filtered by the white list and black list.
    The white list is a list of classifier results that are allowed to pass the filter.
    The black list is a list of classifier results that are not allowed to pass the filter.
    The filter is case sensitive. If the caseSensitive is set to false, the filter is case in-sensitive.

        ========================  =======================
        Input Annotation Types    Output Annotation Type
        ========================  =======================
        ``DOCUMENT, CATEGORY``       ``DOCUMENT``
        ========================  =======================

    Parameters
    ----------
    blackList
        If defined, list of entities to ignore. The rest will be processed.
    whiteList
        If defined, list of entities to process. The rest will be ignored.
    caseSensitive
        Determines whether the definitions of the white listed and black listed entities are case sensitive or not.

    Examples
    --------
    >>> from sparknlp.base import *
    >>> from sparknlp.annotator import *
    >>> from sparknlp_jsl.annotator import *
    >>> from pyspark.ml import Pipeline
    >>> documentAssembler = DocumentAssembler().setInputCol("text").setOutputCol("document")
    >>> sentenceDetector = SentenceDetector().setInputCols("document").setOutputCol("sentence")
    >>> tokenizer = Tokenizer().setInputCols("sentence").setOutputCol("token")
    >>> medicalBFSC = MedicalBertForSequenceClassification.pretrained("bert_sequence_classifier_covid_sentiment", "en", "clinical/models") \\
    ...     .setInputCols(["sentence", "token"]).setOutputCol("classifier") \\
    >>> documentFilterer = DocumentFiltererByClassifier() \\
    ...     .setInputCols(["sentence", "classifier"])\\
    ...     .setOutputCol("filteredDocuments")\\
    ...     .setWhiteList(["Positive"])\\
    ...     .setCaseSensitive(False)
    >>> data = spark.createDataFrame([[
    ...     "British Department of Health confirms first two cases of in UK." +
    ...     "So my trip to visit my australian exchange student just got canceled because of Coronavirus." +
    ...     "I wish everyone to be safe at home and stop pandemic."
    ...     ]]).toDF("text")
    >>> pipeline = Pipeline()\\
    ...     .setStages([documentAssembler, sentenceDetector, tokenizer, medicalBFSC, documentFilterer]).fit(data)
    >>> result = pipeline.transform(data)
    >>> result.selectExpr("filteredDocuments").show(truncate=False)
    +--------------------------------------------------------------------------------------------------+
    |filteredDocuments                                                                                 |
    +--------------------------------------------------------------------------------------------------+
    |[{document, 181, 233, I wish everyone to be safe at home and stop pandemic., {sentence -> 2}, []}]|
    +--------------------------------------------------------------------------------------------------+

    """
    name = "DocumentFiltererByClassifier"
    inputAnnotatorTypes = [AnnotatorType.DOCUMENT, AnnotatorType.CATEGORY]
    outputAnnotatorType = AnnotatorType.DOCUMENT

    def __init__(self, classname="com.johnsnowlabs.nlp.annotators.DocumentFiltererByClassifier", java_model=None):
        super(DocumentFiltererByClassifier, self).__init__(
            classname=classname,
            java_model=java_model
        )
