import sparknlp
import sys
from sparknlp.annotator.param.evaluation_dl_params import EvaluationDLParams
from sparknlp.internal import ExtendedJavaWrapper
from sparknlp_jsl.common import *


class MedicalNerApproach(AnnotatorApproachInternal, sparknlp.annotators.NerApproach, EvaluationDLParams, HasEngine):
    """Trains generic NER models based on Neural Networks.

    The architecture of the neural network is a Char CNNs - BiLSTM - CRF that
    achieves state-of-the-art in most datasets.

    For instantiated/pretrained models, see :class:`.MedicalNerModel`.

    The training data should be a labeled Spark Dataset, in the format of
    :class:`.CoNLL` 2003 IOB with `Annotation` type columns. The data should
    have columns of type ``DOCUMENT, TOKEN, WORD_EMBEDDINGS`` and an additional
    label column of annotator type ``NAMED_ENTITY``.

    Excluding the label, this can be done with for example:

    - a SentenceDetector,
    - a Tokenizer and
    - a WordEmbeddingsModel (any embeddings can be chosen, e.g. BertEmbeddings
      for BERT based embeddings).

    For extended examples of usage, see the `Spark NLP Workshop <https://github.com/JohnSnowLabs/spark-nlp-workshop/tree/master/jupyter/training/english/dl-ner>`__.

    ==================================== ======================
    Input Annotation types               Output Annotation type
    ==================================== ======================
    ``DOCUMENT, TOKEN, WORD_EMBEDDINGS`` ``NAMED_ENTITY``
    ==================================== ======================

    Notes
    -----
        Both DocumentAssembler and SentenceDetector annotators are
        annotators that output the ``DOCUMENT`` annotation type. Thus, any of them
        can be used as the first annotators in a pipeline.

    Parameters
    ----------
    labelColumn: str
        Column with label per each token.
    entities: list
        Entities to recognize.
    minEpochs: int
        Minimum number of epochs to train, by default 0.
    maxEpochs: int
        Maximum number of epochs to train, by default 70.
    verbose: int
        Level of verbosity during training, by default 2.
    randomSeed: int
        Random seed. Set to positive integer to get reproducible results, by default None.
    lr: float
        Learning Rate, by default 0.001.
    po: float
        Learning rate decay coefficient (time-based). This is used to calculate
        the decayed learning rate at each step as: lr = lr / (1 + po * epoch),
        meaning that the value of the learning rate is updated on each epoch. By
        default 0.005.
    batchSize: int
        Batch size, by default 8.
    dropout: float
        Dropout coefficient, by default 0.5.
        
        The coefficient of the dropout layer. The value should be between 0.0 and 1.0.
        Internally, it is used by Tensorflow as: `rate = 1.0 - dropout` when adding
        a dropout layer on top of the recurrent layers.
    graphFolder: str
        Folder path that contains external graph files. The path can be a local file path,
        a distributed file path (HDFS, DBFS), or a cloud storage (S3).
        
        When instantiating the Tensorflow model, uses this folder to search for the
        adequate Tensorflow graph. The search is done using the name of
        the `.pb` file, which should be in this format:
        `blstn_{ntags}_{embedding_dim}_{lstm_size}_{nchars}.pb`.
        Then, the search follows these rules:
        - Embedding dimension should be exactly the same as the one used to train the model.
        - Number of unique tags should be greater than or equal to the number of unique tags
        in the training data.
        - Number of unique chars should be greater than or equal to the number of unique
        chars in the training data.
        
        The returned file will be the first one that satisfies all the conditions.
        
        If the name of the file is ill-formed, errors will occur during training.
    graphFile: str
        Path that contains the external graph file.
        
        When specified, the provided file will be used, and no graph search will happen.
        The path can be a local file path,
        a distributed file path (HDFS, DBFS), or a cloud storage (S3).
    configProtoBytes: list
        ConfigProto from tensorflow, serialized into byte array.
    useContrib: bool
        Whether to use contrib LSTM Cells. Not compatible with Windows. Might
        slightly improve accuracy. By default True.
    validationSplit: float
        Choose the proportion of training dataset to be validated against the
        model on each Epoch. The value should be between 0.0 and 1.0 and by
        default it is 0.0 and off.

        The validation dataset is randomly extracted from the training dataset
        before training starts. If the value is 0.0, then no validation will be
        performed (hold out data).
    evaluationLogExtended: bool
        Whether logs for validation to be extended, by default False.
    testDataset: str
        Path to test dataset in parquet format. If set, the dataset will be used
        to calculate statistic on it during training.
    includeConfidence: bool
        Whether to include confidence scores in annotation metadata, by default
        False.
        
        Setting this parameter to True will add the confidence score to
        the metadata of the NAMED_ENTITY annotation. In addition, if
        `includeAllConfidenceScores` is set to True, then the confidence scores
        of all the tags will be added to the metadata, otherwise only for the
        predicted tag (the one with maximum score).
    includeAllConfidenceScores: bool
        Whether to include confidence scores for all tags in annotation metadata or just
        the score of the predicted tag, by default False.
        
        Needs the `includeConfidence` parameter to be set to True.
        Enabling this may slow down the inference speed.
    enableOutputLogs: bool
        Whether to use stdout in addition to Spark logs, by default False.
    outputLogsPath: str
        Folder path to save training logs. If no path is specified, the logs won't
        be stored in disk. The path can be a local file path,
        a distributed file path (HDFS, DBFS), or a cloud storage (S3).
    enableMemoryOptimizer: bool
        Whether to optimize for large datasets or not. Enabling this option can
        slow down training.

        In practice, if set to True the training will iterate over the spark Data Frame
        and retrieve the batches from the Data Frame iterator. This can be slower
        than the default option as it has to collect the batches on evey bach for every
        epoch, but it can be useful if the dataset is too large to fit in memory.
        
        It controls if we want the features collected and generated at
        once and then feed into the network batch by batch (False) or collected and
        generated by batch and then feed into the network in batches (True) .
        
        If the training data can fit to memory, then it is recommended to set this
        option to False (default value).
    tagsMapping: list
        A map specifying how old tags are mapped to new ones as a list of comma-separated
        entities, where the first entity is the old tag and the second entity is
        the new tag. For example, if the map is set to ["OLDTAG,NEWTAG", "B-PER,B-VIP",
        "I-PER, I-VIP"], then all occurrences of "OLDTAG" will be mapped to "NEWTAG",
        all occurrences of "B-PER" will be mapped to "B-VIP", and all occurrences of
        "I-PER" will be mapped to "I-VIP". It only works if overrideExistingTags
        is set to False.
    earlyStoppingPatience: int
        Number of epochs to wait before early stopping if no improvement, by default 5.
        Given the earlyStoppingCriterion, if the performance does not improve for the given
        number of epochs, then the training will stop. If the value is 0, then early stopping
        will occurs as soon as the criterion is met (no patience).
    earlyStoppingCriterion: float
        If set, this param specifies the criterion to stop training if performance is not improving.
        Default value is 0 which is means that early stopping is not used.
        
        The criterion is set to F1-score if the validationSplit is greater than 0.0
        (F1-socre on validation set) or testDataset is defined (F1-score on test set),
        otherwise it is set to model loss. The priority is as follows:
        - If testDataset is defined, then the criterion is set to F1-score on test set.
        - If validationSplit is greater than 0.0, then the criterion is set to
        F1-score on validation set.
        - Otherwise, the criterion is set to model loss.
        
        Note that while the F1-score ranges from 0.0 to 1.0, the loss ranges
        from 0.0 to infinity. So, depending on which case you are in,
        the value you use for the criterion can be very different. For example,
        if validationSplit is 0.1, then a criterion of 0.01 means that if the F1-score
        on the validation set difference from last epoch is greater than 0.01, then the
        training should stop.
        However, if there is not validation or test set defined, then a criterion of 2.0
        means that if the loss difference between the last epoch and the current one
        is less than 2.0, then training should stop.
        
        See also `earlyStoppingPatience`.
    pretrainedModelPath: str
        Path to an already trained MedicalNerModel.
        
        This pretrained model will be used as a starting point
        for training the new one. The path can be a local file path,
        a distributed file path (HDFS, DBFS), or a cloud storage (S3).
    logPrefix: str
        A prefix that will be appended to every log, default value is empty.
    useBestModel: bool
        Whether to restore and use the model from the epoch that has achieved the
        best performance at the end of the training. By default False (keep the
        model from the last trained epoch).
        
        The best model depends on the earlyStoppingCriterion, which can be F1-score
        on test/validation dataset or the value of loss.
    overrideExistingTags
        Whether to override the already learned tags when using a pretrained model
        to initialize the new model. A value of `True` (default) will override
        existing tags.
    sentenceTokenIndex: bool
        Whether to include the token index for each sentence in annotation metadata, by default False.
        If the value is True, the process might be slowed down.

    Examples
    --------
    >>> import sparknlp
    >>> from sparknlp.base import *
    >>> from sparknlp_jsl.common import *
    >>> from sparknlp.annotator import *
    >>> from sparknlp.training import *
    >>> import sparknlp_jsl
    >>> from sparknlp_jsl.base import *
    >>> from sparknlp_jsl.annotator import *
    >>> from pyspark.ml import Pipeline

    First extract the prerequisites for the MedicalNerApproach

    >>> documentAssembler = DocumentAssembler() \\
    ...     .setInputCol("text") \\
    ...     .setOutputCol("document")
    >>> sentence = SentenceDetector() \\
    ...     .setInputCols(["document"]) \\
    ...     .setOutputCol("sentence")
    >>> tokenizer = Tokenizer() \\
    ...     .setInputCols(["sentence"]) \\
    ...     .setOutputCol("token")
    >>> embeddings = BertEmbeddings.pretrained() \\
    ...     .setInputCols(["sentence", "token"]) \\
    ...     .setOutputCol("embeddings")

    Then the training can start

    >>> nerTagger = MedicalNerApproach() \\
    ...     .setInputCols(["sentence", "token", "embeddings"]) \\
    ...     .setLabelColumn("label") \\
    ...     .setOutputCol("ner") \\
    ...     .setMaxEpochs(1) \\
    ...     .setRandomSeed(0) \\
    ...     .setVerbose(0)
    >>> pipeline = Pipeline().setStages([
    ...     documentAssembler,
    ...     sentence,
    ...     tokenizer,
    ...     embeddings,
    ...     nerTagger
    ... ])
    >>> conll = CoNLL()
    >>> trainingData = conll.readDataset(spark, "src/test/resources/conll2003/eng.train")
    >>> pipelineModel = pipeline.fit(trainingData)
    """
    inputAnnotatorTypes = [AnnotatorType.DOCUMENT, AnnotatorType.TOKEN, AnnotatorType.WORD_EMBEDDINGS]
    outputAnnotatorType = AnnotatorType.NAMED_ENTITY

    lr = Param(Params._dummy(), "lr", "Learning Rate", TypeConverters.toFloat)

    po = Param(Params._dummy(), "po", "Learning rate decay coefficient. Real Learning Rate = lr / (1 + po * epoch)",
               TypeConverters.toFloat)

    batchSize = Param(Params._dummy(), "batchSize", "Batch size", TypeConverters.toInt)

    dropout = Param(Params._dummy(), "dropout", "Dropout coefficient", TypeConverters.toFloat)

    graphFolder = Param(Params._dummy(), "graphFolder", "Folder path that contains external graph files",
                        TypeConverters.toString)

    graphFile = Param(Params._dummy(), "graphFile",
                      "Path that contains the external graph file. When specified, the provided file will be used, and no graph search will happen.",
                      TypeConverters.toString)

    configProtoBytes = Param(Params._dummy(), "configProtoBytes",
                             "ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()",
                             TypeConverters.toListString)

    useContrib = Param(Params._dummy(), "useContrib",
                       "whether to use contrib LSTM Cells. Not compatible with Windows. Might slightly improve accuracy.",
                       TypeConverters.toBoolean)

    includeConfidence = Param(Params._dummy(), "includeConfidence",
                              "whether to include confidence scores in annotation metadata",
                              TypeConverters.toBoolean)

    includeAllConfidenceScores = Param(Params._dummy(), "includeAllConfidenceScores",
                                       "whether to include all confidence scores in annotation metadata or just the score of the predicted tag",
                                       TypeConverters.toBoolean)

    logPrefix = Param(Params._dummy(), "logPrefix",
                      "A prefix that will be appended to every log, default value is empty.", TypeConverters.toString)

    enableMemoryOptimizer = Param(Params._dummy(), "enableMemoryOptimizer",
                                  "Whether to optimize for large datasets or not. Enabling this option can slow down training.",
                                  TypeConverters.toBoolean)

    useBestModel = Param(Params._dummy(), "useBestModel",
                         "Whether to restore and use the model from the epoch that has achieved the best performance at the end of the training.",
                         TypeConverters.toBoolean)

    pretrainedModelPath = Param(Params._dummy(), "pretrainedModelPath",
                                "Path to an already trained MedicalNerModel, which is used as a starting point for training the new model.",
                                TypeConverters.toString)

    overrideExistingTags = Param(Params._dummy(), "overrideExistingTags",
                                 "Whether to override already learned tags when using a pretrained model to initialize the new model. Default is 'true'.",
                                 TypeConverters.toBoolean)

    # tagsMapping = Param(Params._dummy(), "tagsMapping",
    #                     "A map specifying how old tags are mapped to new ones. It only works if setOverrideExistingTags "
    #                     + "is false. The mapping is specified as a list of comma separared strings, "
    #                       "e.g. [\"B-PER, B-VIP\", \"I-PER, I-VIP\",...]", TypeConverters.toListString)

    earlyStoppingCriterion = Param(Params._dummy(), "earlyStoppingCriterion",
                                   "If set, this param specifies the criterion to stop training if performance is not improving. "
                                   "Default value is 0 which is means that early stopping is not used.",
                                   TypeConverters.toFloat)

    earlyStoppingPatience = Param(Params._dummy(), "earlyStoppingPatience",
                                  "Number of epochs with no performance improvement before training is terminated. "
                                  "Default value is 0.", TypeConverters.toInt)

    randomValidationSplitPerEpoch = Param(Params._dummy(), "randomValidationSplitPerEpoch",
                                          "Do a random validation split after each epoch rather than at the beginning of training only. "
                                          "Default value is 'true'.", TypeConverters.toBoolean)

    sentenceTokenIndex = Param(Params._dummy(), "sentenceTokenIndex",
                               "Whether to include the token index for each sentence in annotation metadata.",
                               TypeConverters.toBoolean)

    def setConfigProtoBytes(self, value: list):
        """Sets configProto from tensorflow, serialized into byte array.

        Parameters
        ----------
        value : List[str]
            ConfigProto from tensorflow, serialized into byte array
        """
        return self._set(configProtoBytes=value)

    def setGraphFolder(self, value: str):
        """Sets folder path that contain external graph files.

        Parameters
        ----------
        value : str
            Folder path that contain external graph files
        """
        return self._set(graphFolder=value)

    def setGraphFile(self, value: str):
        """Sets path that contains the external graph file. When specified, the provided file will be used, and no graph search will happen.

        Parameters
        ----------
        value : str
            Path that contains the external graph file. When specified, the provided file will be used, and no graph search will happen.
        """
        return self._set(graphFile=value)

    def setUseContrib(self, value: bool):
        """Sets whether to use contrib LSTM Cells. Not compatible with Windows.
        Might slightly improve accuracy.

        Parameters
        ----------
        value : bool
            Whether to use contrib LSTM Cells

        Raises
        ------
        Exception
            Windows not supported to use contrib
        """
        if value and sys.version == 'win32':
            raise Exception("Windows not supported to use contrib")
        return self._set(useContrib=value)

    def setLr(self, value: float):
        """Sets Learning Rate, by default 0.001.

        Parameters
        ----------
        value : float
            Learning Rate
        """
        self._set(lr=value)
        return self

    def setPo(self, value: float):
        """Sets Learning rate decay coefficient, by default 0.005.

        Real Learning Rage is lr / (1 + po * epoch).

        Parameters
        ----------
        value : float
            Learning rate decay coefficient
        """
        self._set(po=value)
        return self

    def setBatchSize(self, value: int):
        """Sets batch size, by default 64.

        Parameters
        ----------
        value : int
            Batch size
        """
        self._set(batchSize=value)
        return self

    def setDropout(self, value: float):
        """Sets dropout coefficient, by default 0.5.

        Parameters
        ----------
        value : float
            Dropout coefficient
        """
        self._set(dropout=value)
        return self

    def _create_model(self, java_model):
        """Creates the model using the java model.
        Args:
            java_model (str): The name of the java model.
        """
        return MedicalNerModel(java_model=java_model)

    def setValidationSplit(self, value: float):
        """Sets the proportion of training dataset to be validated against the
        model on each Epoch, by default it is 0.0 and off. The value should be
        between 0.0 and 1.0.

        Parameters
        ----------
        value : float
            Proportion of training dataset to be validated
        """
        self._set(validationSplit=value)
        return self

    def setIncludeConfidence(self, value: bool):
        """Sets whether to include confidence scores in annotation metadata, by
        default False.

        Parameters
        ----------
        value : bool
            Whether to include the confidence value in the output.
        """
        return self._set(includeConfidence=value)

    def setIncludeAllConfidenceScores(self, value: bool):
        """Sets whether to include all confidence scores in annotation metadata
        or just the score of the predicted tag, by default False.

        Parameters
        ----------
        value : bool
            Whether to include all confidence scores in annotation metadata or
            just the score of the predicted tag
        """
        return self._set(includeAllConfidenceScores=value)
    def setDoExceptionHandling(self, value: bool):
        """If true, tries to compute batch-wise as usual.
    If within a batch an exception occurs, the batch will be processed row-wise and for any exception occurring during row-processing a Error Annotation is emitted.
    This means only the bad rows are lost instead of entire batch.
    This comes with a performance penalty.

        Parameters
        ----------
        value : bool
        """
        return self._set(doExceptionHandling=value)



    def setEnableMemoryOptimizer(self, value: bool):
        """Sets Whether to optimize for large datasets or not, by default False.
        Enabling this option can slow down training.

        Parameters
        ----------
        value : bool
            Whether to optimize for large datasets
        """
        return self._set(enableMemoryOptimizer=value)

    def setUseBestModel(self, value: bool):
        """Sets whether to return the model that has achieved the best metrics across epochs.

        Parameters
        ----------
        value : bool
            Whether to return the model that has achieved the best metrics across epochs.
        """
        return self._set(useBestModel=value)

    def setLogPrefix(self, value: str):
        """Sets the prefix of the training logs.

        Parameters
        ----------
        value : str
            A prefix that will be appended to every log, default value is empty.
        """
        return self._set(logPrefix=value)

    def setPretrainedModelPath(self, value: str):
        """Sets location of pretrained model.

        Parameters
        ----------
        value : str
           Path to an already trained MedicalNerModel, which is used as a starting point for training the new model.
        """
        return self._set(pretrainedModelPath=value)

    def setOverrideExistingTags(self, value: bool):
        """Sets whether to override already learned tags when using a pretrained model to initialize the new model. Default is 'true'

        Parameters
        ----------
        value : bool
            Whether to override already learned tags when using a pretrained model to initialize the new model. Default is 'true'
        """
        return self._set(overrideExistingTags=value)

    def setTagsMapping(self, value: list):
        """Sets a map specifying how old tags are mapped to new ones.
    
        The format of the map should be a list of comma-separated entities, where the
        first entity is the old tag and the second entity is the new tag. For example,
        if the map is set to ["OLDTAG,NEWTAG", "B-PER,B-VIP", "I-PER, I-VIP"], then all
        occurrences of "OLDTAG" will be mapped to "NEWTAG", all occurrences of "B-PER" will
        be mapped to "B-VIP", and all occurrences of "I-PER" will be mapped to "I-VIP".
        
        It only works if setOverrideExistingTags is set to False.

        Parameters
        ----------
        value : List[str]
            List of comma-separated entities.
        """

        self._call_java("setTagsMapping", value)

        return self

    def setEarlyStoppingCriterion(self, criterion: float):
        """Sets early stopping criterion. A value 0 means no early stopping.

        Parameters
        ----------
        criterion : float
            Early stopping criterion.
        """
        return self._set(earlyStoppingCriterion=criterion)

    def setEarlyStoppingPatience(self, patience: int):
        """Sets the number of epochs with no performance improvement before training is terminated.

        Parameters
        ----------
        patience : int
            Early stopping patience.
        """
        return self._set(earlyStoppingPatience=patience)

    def setRandomValidationSplitPerEpoch(self, value: bool):
        """Do a random validation split after each epoch rather than at the beginning of training only.

        Parameters
        ----------
        value : bool
            Whether to do a random validation split after each epoch.
        """
        return self._set(randomValidationSplitPerEpoch=value)

    def setSentenceTokenIndex(self, value: bool):
        """ Sets whether to include the token index for each sentence in annotation metadata,
         by default False. If the value is True, the process might be slowed down.

        Parameters
        ----------
        value : bool
            Whether to include the token index for each sentence in annotation metadata, by default False.
            If the value is True, the process might be slowed down.
        """
        return self._set(sentenceTokenIndex=value)

    @keyword_only
    def __init__(self):
        super(MedicalNerApproach, self).__init__(classname="com.johnsnowlabs.nlp.annotators.ner.MedicalNerApproach")
        uc = False if sys.platform == 'win32' else True
        self._setDefault(
            minEpochs=0,
            maxEpochs=50,
            lr=float(0.001),
            po=float(0.005),
            batchSize=8,
            dropout=float(0.5),
            useContrib=uc,
            includeConfidence=False,
            includeAllConfidenceScores=False,
            enableMemoryOptimizer=False,
            pretrainedModelPath="",
            overrideExistingTags=True,
            earlyStoppingCriterion=0.0,
            earlyStoppingPatience=0,
            randomValidationSplitPerEpoch=False,
            sentenceTokenIndex=False
        )


class _MedicalNerModelLoader(ExtendedJavaWrapper):
    """Internal class to load a MedicalNerModel from a path.
    """

    def __init__(self, ner_model_path, path, jspark):
        super(_MedicalNerModelLoader, self).__init__(
            "com.johnsnowlabs.nlp.annotators.ner.MedicalNerModel.loadSavedModel", ner_model_path, path, jspark)


class MedicalNerModel(AnnotatorModelInternal, HasStorageRef, HasBatchedAnnotate):
    """This Named Entity recognition annotator is a generic NER model based on
    Neural Networks.

    Neural Network architecture is Char CNNs - BiLSTM - CRF that achieves
    state-of-the-art in most datasets.

    This is the instantiated model of the :class:`.NerDLApproach`. For training
    your own model, please see the documentation of that class.

    Pretrained models can be loaded with :meth:`.pretrained` of the companion
    object:

    >>> nerModel = MedicalNerDLModel.pretrained() \\
    ...     .setInputCols(["sentence", "token", "embeddings"]) \\
    ...     .setOutputCol("ner")


    The default model is ``"ner_dl"``, if no name is provided.

    For available pretrained models please see the `Models Hub
    <https://nlp.johnsnowlabs.com/models?task=Named+Entity+Recognition>`__.
    Additionally, pretrained pipelines are available for this module, see
    `Pipelines <https://nlp.johnsnowlabs.com/docs/en/pipelines>`__.

    Note that some pretrained models require specific types of embeddings,
    depending on which they were trained on. For example, the default model
    ``"ner_dl"`` requires the WordEmbeddings ``"glove_100d"``.

    For extended examples of usage, see the `Spark NLP Workshop
    <https://github.com/JohnSnowLabs/spark-nlp-workshop/blob/master/tutorials/Certification_Trainings/Public/3.SparkNLP_Pretrained_Models.ipynb>`__.

    ==================================== ======================
    Input Annotation types               Output Annotation type
    ==================================== ======================
    ``DOCUMENT, TOKEN, WORD_EMBEDDINGS`` ``NAMED_ENTITY``
    ==================================== ======================

    Parameters
    ----------
    batchSize
        Size of every batch, by default 8
    configProtoBytes
        ConfigProto from tensorflow, serialized into byte array.
    includeConfidence
        Whether to include confidence scores in annotation metadata, by default
        False
    includeAllConfidenceScores
        Whether to include all confidence scores in annotation metadata or just
        the score of the predicted tag, by default False
    inferenceBatchSize
        Number of sentences to process in a single batch during inference
    classes
        Tags used to trained this NerDLModel
    labelCasing:
        Setting all labels of the NER models upper/lower case. values upper|lower
    sentenceTokenIndex
        Whether to include the token index for each sentence in annotation metadata, by default False.
        If the value is True, the process might be slowed down.

    Examples
    --------
    >>> import sparknlp
    >>> from sparknlp.base import *
    >>> from sparknlp_jsl.common import *
    >>> from sparknlp.annotator import *
    >>> from sparknlp.training import *
    >>> import sparknlp_jsl
    >>> from sparknlp_jsl.base import *
    >>> from sparknlp_jsl.annotator import *
    >>> from pyspark.ml import Pipeline
    >>> documentAssembler = DocumentAssembler() \\
    ...     .setInputCol("text") \\
    ...     .setOutputCol("document")
    >>> sentence = SentenceDetector() \\
    ...     .setInputCols(["document"]) \\
    ...     .setOutputCol("sentence")
    >>> tokenizer = Tokenizer() \\
    ...     .setInputCols(["sentence"]) \\
    ...     .setOutputCol("token")
    >>> embeddings = WordEmbeddingsModel.pretrained() \\
    ...     .setInputCols(["sentence", "token"]) \\
    ...     .setOutputCol("bert")
    >>> nerTagger = MedicalNerDLModel.pretrained() \\
    ...     .setInputCols(["sentence", "token", "bert"]) \\
    ...     .setOutputCol("ner")
    >>> pipeline = Pipeline().setStages([
    ...     documentAssembler,
    ...     sentence,
    ...     tokenizer,
    ...     embeddings,
    ...     nerTagger
    ... ])
    >>> data = spark.createDataFrame([["U.N. official Ekeus heads for Baghdad."]]).toDF("text")
    >>> result = pipeline.fit(data).transform(data)
    """
    name = "MedicalNerModel"
    inputAnnotatorTypes = [AnnotatorType.DOCUMENT, AnnotatorType.TOKEN, AnnotatorType.WORD_EMBEDDINGS]
    outputAnnotatorType = AnnotatorType.NAMED_ENTITY

    def __init__(self, classname="com.johnsnowlabs.nlp.annotators.ner.MedicalNerModel", java_model=None):
        super(MedicalNerModel, self).__init__(
            classname=classname,
            java_model=java_model
        )
        self._setDefault(
            includeConfidence=False,
            includeAllConfidenceScores=False,
            batchSize=8,
            inferenceBatchSize=1,
            sentenceTokenIndex=False
        )

    configProtoBytes = Param(Params._dummy(), "configProtoBytes",
                             "ConfigProto from tensorflow, serialized into byte array. Get with config_proto.SerializeToString()",
                             TypeConverters.toListString)
    includeConfidence = Param(Params._dummy(), "includeConfidence",
                              "whether to include confidence scores in annotation metadata",
                              TypeConverters.toBoolean)
    includeAllConfidenceScores = Param(Params._dummy(), "includeAllConfidenceScores",
                                       "whether to include all confidence scores in annotation metadata or just the score of the predicted tag",
                                       TypeConverters.toBoolean)

    doExceptionHandling = Param(Params._dummy(), "doExceptionHandling","""If true, tries to compute batch-wise as usual.
    If within a batch an exception occurs, the batch will be processed row-wise and for any exception occurring during row-processing a Error Annotation is emitted.
    This means only the bad rows are lost instead of entire batch.
    This comes with a performance penalty.""",TypeConverters.toBoolean)

    inferenceBatchSize = Param(Params._dummy(), "inferenceBatchSize",
                               "number of sentences to process in a single batch during inference",
                               TypeConverters.toInt)
    classes = Param(Params._dummy(), "classes",
                    "get the tags used to trained this MedicalNerModel",
                    TypeConverters.toListString)

    trainingClassDistribution = Param(Params._dummy(),
                                      "trainingClassDistribution",
                                      "class counts for each of the classes during training",
                                      typeConverter=TypeConverters.identity)

    labelCasing = Param(Params._dummy(), "labelCasing",
                        "Setting all labels of the NER models upper/lower case. values upper|lower",
                        TypeConverters.toString)

    sentenceTokenIndex = Param(Params._dummy(), "sentenceTokenIndex",
                               "Whether to include the token index for each sentence in annotation metadata.",
                               TypeConverters.toBoolean)

    def setConfigProtoBytes(self, conf: list):
        """Sets configProto from tensorflow, serialized into byte array.

        Parameters
        ----------
        conf : List[str]
            ConfigProto from tensorflow, serialized into byte array
        """
        return self._set(configProtoBytes=conf)

    def setIncludeConfidence(self, value: bool):
        """Sets whether to include confidence scores in annotation metadata, by
        default False.

        Parameters
        ----------
        value : bool
            Whether to include the confidence value in the output.
        """
        return self._set(includeConfidence=value)

    def setInferenceBatchSize(self, value: int):
        """Sets number of sentences to process in a single batch during inference

        Parameters
        ----------
        value : int
           number of sentences to process in a single batch during inference
        """
        return self._set(inferenceBatchSize=value)

    def setLabelCasing(self, value: str):
        """Setting all labels of the NER models upper/lower case. values upper|lower

        Parameters
        ----------
        value : str
           Setting all labels of the NER models upper/lower case. values upper|lower
        """
        return self._set(labelCasing=value)

    def setSentenceTokenIndex(self, value: bool):
        """ Sets whether to include the token index for each sentence in annotation metadata,
        by default False. If the value is True, the process might be slowed down.

        Parameters
        ----------
        value : bool
            Whether to include the token index for each sentence in annotation metadata, by default False.
            If the value is True, the process might be slowed down.
        """
        return self._set(sentenceTokenIndex=value)

    def getTrainingClassDistribution(self):
        """Gets the class counts for each of the classes during training.
        """
        return self._call_java('getTrainingClassDistributionJava')

    def getClasses(self):
        """
        Returns the list of entities which are recognized
        """
        return self._call_java("getClasses")

    @staticmethod
    def loadSavedModel(ner_model_path, folder, spark_session):
        """Load a pre-trained MedicalNerModel.
        
        Args:
            ner_model_path (str): Path to the pre-trained model.
            folder (str): Folder where the Tensorflow model is located.
            spark_session (SparkSession): SparkSession.
        
        Returns:
            MedicalNerModel: A pre-trained MedicalNerModel.
        """
        jModel = _MedicalNerModelLoader(ner_model_path, folder, spark_session._jsparkSession)._java_obj
        return MedicalNerModel(java_model=jModel)

    @staticmethod
    def pretrained(name="ner_jsl", lang="en", remote_loc="clinical/models"):
        """Download a pre-trained MedicalNerModel.
        
        Args:
            name (str): Name of the pre-trained model, by default "ner_jsl"
            lang (str): Language of the pre-trained model, by default "en"
            remote_loc (str): Remote location of the pre-trained model. If None, use the
            open-source location. Other values are "clinical/models",
            "finance/models", or "legal/models".
        
        Returns:
            MedicalNerModel: A pre-trained MedicalNerModel.
        """
        from sparknlp_jsl.pretrained import InternalResourceDownloader
        return InternalResourceDownloader.downloadModel(MedicalNerModel, name, lang, remote_loc,
                                                        j_dwn='InternalsPythonResourceDownloader')
