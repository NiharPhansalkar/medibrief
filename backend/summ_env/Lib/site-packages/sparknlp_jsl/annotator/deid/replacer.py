from pyspark import keyword_only
from pyspark.ml.param import TypeConverters, Params, Param
from sparknlp.internal import AnnotatorTransformer

from sparknlp_jsl.common import AnnotatorModelInternal, AnnotatorType


class Replacer(AnnotatorModelInternal):
    """Replaces entities in the original text with new ones.

    This class allows to replace entities in the original text with the ones obtained with,
    for example, :py:class:`DeIdentificationModel`_ or :py:class:`DateNormalizer`_.

    Attributes:
        useReplacement (bool): Enable or disable Replacement of entities. Default: True.

    Examples:

    >>> documentAssembler = DocumentAssembler()\\
    ...     .setInputCol("text")\\
    ...     .setOutputCol("sentence")

    >>> tokenizer = Tokenizer()\\
    ...     .setInputCols("sentence")\\
    ...     .setOutputCol("token")

    >>> word_embeddings = WordEmbeddingsModel.pretrained("embeddings_clinical", "en", "clinical/models")\\
    ...         .setInputCols(["sentence", "token"])\\
    ...         .setOutputCol("embeddings")

    >>> clinical_ner = MedicalNerModel.pretrained("ner_deid_generic_augmented", "en", "clinical/models") \\
    ...         .setInputCols(["sentence", "token", "embeddings"]) \\
    ...         .setOutputCol("ner")

    >>> ner_converter_name = NerConverterInternal()\\
    ...         .setInputCols(["sentence","token","ner"])\\
    ...         .setOutputCol("ner_chunk")

    >>> nameChunkObfuscator = NameChunkObfuscatorApproach()\\
    ...     .setInputCols("ner_chunk")\\
    ...     .setOutputCol("replacement")\\
    ...     .setRefFileFormat("csv")\\
    ...     .setObfuscateRefFile("names_test.txt")\\
    ...     .setRefSep("#")

    >>> replacer_name = Replacer()\\
    ...     .setInputCols("replacement","sentence")\\
    ...     .setOutputCol("obfuscated_document_name")\\
    ...     .setUseReplacement(True)

    >>> nlpPipeline = Pipeline(stages=[
    ...         documentAssembler,
    ...         tokenizer,
    ...         word_embeddings,
    ...         clinical_ner,
    ...         ner_converter_name,
    ...         nameChunkObfuscator,
    ...         replacer_name,
    ...         ])

    >>> empty_data = spark.createDataFrame([[""]]).toDF("text")
    >>> model_chunck_obfuscator = nlpPipeline.fit(empty_data)
    >>> sample_text = '''John Davies is a 62 y.o. patient admitted. Mr. Davies was seen by attending physician Dr. Lorand and was scheduled for emergency assessment.'''
    >>> lmodel = LightPipeline(model_chunck_obfuscator)
    >>> res = lmodel.fullAnnotate(sample_text)
    >>> print("Original text.  : ", res[0]['sentence'][0].result)
    >>> print("Obfuscated text : ", res[0]['obfuscated_document_name'][0].result)
    Original text.  :  John Davies is a 62 y.o. patient admitted. Mr. Davies was seen by attending physician Dr. Lorand and was scheduled for emergency assessment.
    Obfuscated text :  Fitzpatrick is a <AGE> y.o. patient admitted. Mr. Bowman was seen by attending physician Dr. Acosta and was scheduled for emergency assessment.
    """
    name = "Replacer"
    inputAnnotatorTypes = [AnnotatorType.DOCUMENT, AnnotatorType.CHUNK]
    outputAnnotatorType = AnnotatorType.DOCUMENT
    useReplacement = Param(Params._dummy(), "useReplacement", "I",
                           TypeConverters.toBoolean)


    def __init__(self, classname="com.johnsnowlabs.nlp.annotators.deid.Replacer", java_model=None):
        super(Replacer, self).__init__(
            classname=classname,
            java_model=java_model
        )

    def setUseReplacement(self, value: bool):
        """Enable or disable Replacement of entities

        Parameters
        ----------
        value : bool
            True for Replacing, False otherwise.
        """
        return self._set(useReplacement=value)

    def getUseReplacement(self):
        """Gets the value of useReplacement or its default value.
        """
        return self.getOrDefault(self.useReplacement)
